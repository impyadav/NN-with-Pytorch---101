{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63e6a193",
   "metadata": {},
   "source": [
    "# Transformer - Implemenation from scratch using pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755a9314",
   "metadata": {},
   "source": [
    "Part of **#30DaysOfBasics**, Lets build a chatbot application using Encoder-Decoder (transformer based) architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df42c72b",
   "metadata": {},
   "source": [
    "Training Data: Cornell Movies dialogs (https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html)\n",
    "\n",
    "Referencev tutorial: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21e678d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import re\n",
    "import json\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11d2ab93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\n",
      "L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\n",
      "L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\n",
      "L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\n",
      "L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\n",
      "L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\n",
      "L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\n",
      "L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No\n"
     ]
    }
   ],
   "source": [
    "corpus_movie_convo = '../data/movie_conversations.txt'\n",
    "corpus_movie_lines = '../data/movie_lines.txt'\n",
    "\n",
    "with open(corpus_movie_convo, 'r', encoding='iso-8859-1') as f:\n",
    "    movie_convo = f.readlines()\n",
    "    \n",
    "with open(corpus_movie_lines, 'r', encoding='iso-8859-1') as f:\n",
    "    movie_lines = f.readlines()\n",
    "\n",
    "for line in movie_lines[:8]:\n",
    "    print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99b1391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_dic = {}\n",
    "for line in movie_lines:\n",
    "    objects = line.split(\" +++$+++ \")\n",
    "    lines_dic[objects[0]] = objects[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72207cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(string):\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    no_punct = \"\"\n",
    "    for char in string:\n",
    "        if char not in punctuations:\n",
    "            no_punct = no_punct + char  # space is also a character\n",
    "    return no_punct.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48204b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 25\n",
    "\n",
    "\n",
    "pairs = []\n",
    "for con in movie_convo:\n",
    "    ids = eval(con.split(\" +++$+++ \")[-1])\n",
    "    for i in range(len(ids)):\n",
    "        qa_pairs = []\n",
    "        \n",
    "        if i==len(ids)-1:\n",
    "            break\n",
    "        \n",
    "        first = remove_punc(lines_dic[ids[i]].strip())      \n",
    "        second = remove_punc(lines_dic[ids[i+1]].strip())\n",
    "        qa_pairs.append(first.split()[:MAX_LEN])\n",
    "        qa_pairs.append(second.split()[:MAX_LEN])\n",
    "        pairs.append(qa_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08091d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = Counter()\n",
    "for pair in pairs:\n",
    "    word_freq.update(pair[0])\n",
    "    word_freq.update(pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a3974cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_word_freq = 5\n",
    "words = [w for w in word_freq.keys() if word_freq[w] > min_word_freq]\n",
    "word_map = {k: v + 1 for v, k in enumerate(words)}\n",
    "word_map['<unk>'] = len(word_map) + 1\n",
    "word_map['<start>'] = len(word_map) + 1\n",
    "word_map['<end>'] = len(word_map) + 1\n",
    "word_map['<pad>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f22ba794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/WORDMAP_corpus.json', 'w') as j:\n",
    "#     json.dump(word_map, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb0abe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_question(words, word_map, max_len=MAX_LEN):\n",
    "    enc_c = [word_map.get(word, word_map['<unk>']) for word in words] + [word_map['<pad>']] * (max_len - len(words))\n",
    "    return enc_c\n",
    "\n",
    "\n",
    "def encode_reply(words, word_map, max_len=MAX_LEN):\n",
    "    enc_c = [word_map['<start>']] + [word_map.get(word, word_map['<unk>']) for word in words] + \\\n",
    "    [word_map['<end>']] + [word_map['<pad>']] * (max_len - len(words))\n",
    "    return enc_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca4711f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_encoded = []\n",
    "for pair in pairs:\n",
    "    qus = encode_question(pair[0], word_map)\n",
    "    ans = encode_reply(pair[1], word_map)\n",
    "    pairs_encoded.append([qus, ans])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "764b0cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/pairs_encoded.json', 'w') as p:\n",
    "#     json.dump(pairs_encoded, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e0f3e1",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d96df355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "514dc7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.pairs = json.load(open('../data/pairs_encoded.json'))\n",
    "        self.dataset_size = len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        question = torch.LongTensor(self.pairs[i][0])\n",
    "        reply = torch.LongTensor(self.pairs[i][1])\n",
    "            \n",
    "        return question, reply\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a656de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(Dataset(),\n",
    "                        batch_size = 100, \n",
    "                        shuffle=True, \n",
    "                        pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f868892e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6983,  725,   17,  ...,    0,    0,    0],\n",
      "        [  26,   29,   17,  ...,    0,    0,    0],\n",
      "        [ 100,  113,   20,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [8543,  295,   82,  ...,    0,    0,    0],\n",
      "        [  56,   55, 1732,  ...,    0,    0,    0],\n",
      "        [  56,   57,  909,  ...,    0,    0,    0]]) tensor([[18241,    17,  8386,  ...,     0,     0,     0],\n",
      "        [18241,  7652,    91,  ...,     0,     0,     0],\n",
      "        [18241,   929,   399,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [18241,    87,    29,  ...,     0,     0,     0],\n",
      "        [18241,   347,    93,  ...,     0,     0,     0],\n",
      "        [18241,  5518,  1239,  ...,     0,     0,     0]])\n",
      "torch.Size([100, 25]) torch.Size([100, 27])\n"
     ]
    }
   ],
   "source": [
    "qes, rply = next(iter(train_loader))\n",
    "print(qes, rply)\n",
    "print(qes.shape, rply.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6740270c",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "39d506e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(question, reply_input, reply_target):\n",
    "    \n",
    "    def subsequent_mask(size):\n",
    "        mask = torch.triu(torch.ones(size, size)).transpose(0, 1).type(dtype=torch.uint8)\n",
    "        return mask.unsqueeze(0)\n",
    "    \n",
    "    question_mask = question!=0\n",
    "    question_mask = question_mask.to(device)\n",
    "    question_mask = question_mask.unsqueeze(1).unsqueeze(1)         # (batch_size, 1, 1, max_words)\n",
    "     \n",
    "    reply_input_mask = reply_input!=0\n",
    "    reply_input_mask = reply_input_mask.unsqueeze(1)  # (batch_size, 1, max_words)\n",
    "    reply_input_mask = reply_input_mask & subsequent_mask(reply_input.size(-1)).type_as(reply_input_mask.data) \n",
    "    reply_input_mask = reply_input_mask.unsqueeze(1) # (batch_size, 1, max_words, max_words)\n",
    "    reply_target_mask = reply_target!=0              # (batch_size, max_words)\n",
    "    \n",
    "    return question_mask, reply_input_mask, reply_target_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3a5b2fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, d_model, max_len=50):\n",
    "        super(Embeddings, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        self.pe = self.create_positional_encoding(max_len, d_model)\n",
    "     \n",
    "    \n",
    "    def create_positional_encoding(self, max_len, d_model):\n",
    "            \n",
    "        pe = torch.zeros(max_len, d_model).to(device)\n",
    "            \n",
    "        for pos in range(max_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2* i) / d_model)))\n",
    "                pe[pos, i+1] = math.cos(pos / (10000 ** ((2* (i + 1)) / d_model)))\n",
    "                    \n",
    "        pe = torch.unsqueeze(pe, 0) #(1, max_len, d_model)\n",
    "        return pe\n",
    "    \n",
    "    \n",
    "    def forward(self, encoded_words):\n",
    "        embeddings = self.embed(encoded_words) * math.sqrt(d_model) #(batch_size, max_words, d_model)\n",
    "        \n",
    "        embeddings += self.pe[:, :embeddings.size(1)]\n",
    "        \n",
    "        embeddings = self.dropout(embeddings)\n",
    "        \n",
    "        return embeddings   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0938dc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, heads, d_model):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        \n",
    "        assert d_model % heads == 0\n",
    "        self.heads = heads\n",
    "        self.d_k = d_model // heads\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        self.query = nn.Linear(d_model, d_model)\n",
    "        self.key = nn.Linear(d_model, d_model)\n",
    "        self.value = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        self.concat = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    \n",
    "    def forward(self, query, key, value, mask):\n",
    "        \n",
    "        query = self.query(query) #(batch_size, max_len, 512)\n",
    "        key = self.key(key) #(batch_size, max_len, 512)\n",
    "        value = self.value(value) #(batch_size, max_len, 512)\n",
    "        \n",
    "        # (batch_size, max_len, 512) --> (batch_size, max_len, h, d_k) --> (batch_size, h, max_len, d_k)\n",
    "        query = query.view(query.size(0), -1, self.heads, self.d_k).permute(0,2,1,3)\n",
    "        key = key.view(key.size(0), -1, self.heads, self.d_k).permute(0,2,1,3)\n",
    "        value = value.view(value.size(0), -1, self.heads, self.d_k).permute(0,2,1,3)\n",
    "        \n",
    "        # (batch_size, h, max_len, d_k) matmul (batch_size, h, d_k, max_len) --> (batch_size, h, max_len, max_len)\n",
    "        scores = torch.matmul(query, key.permute(0,1,3,2)) / math.sqrt(query.size(-1))\n",
    "        \n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        attn_weights = nn.functional.softmax(scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        # (batch_size, h, max_len, max_len) matmul (batch_size, h, max_len, d_k) --> (batch_size, h, max_len, d_k)\n",
    "        context = torch.matmul(attn_weights, value)\n",
    "        \n",
    "        # (batch_size, h, max_len, d_k) --> (batch_size, max_len, h, d_k) --> (batch_size, max_len, h * d_k)\n",
    "        context = context.permute(0,2,1,3).contiguous().view(context.size(0), -1, self.heads * self.d_k)\n",
    "        \n",
    "        interacted = self.concat(context)\n",
    "        \n",
    "        return interacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "39290c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, middle_dim = 2048):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, middle_dim)\n",
    "        self.fc2 = nn.Linear(middle_dim, d_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = nn.functional.relu(self.fc1(x))\n",
    "        out = self.fc2(self.dropout(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "960a69f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, heads):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        \n",
    "        self.self_multihead = MultiHeadAttention(heads, d_model)\n",
    "        self.feed_forward = FeedForward(d_model)\n",
    "        self.layerNorm = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    \n",
    "    def forward(self, embeddings, mask):\n",
    "        \n",
    "        interacted = self.dropout(self.self_multihead(embeddings, embeddings, embeddings, mask))\n",
    "        interacted = self.layerNorm(interacted + embeddings)\n",
    "        \n",
    "        feed_forward_out = self.dropout(self.feed_forward(interacted))\n",
    "        \n",
    "        encoded = self.layerNorm(feed_forward_out + interacted)\n",
    "        \n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1a95db73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \n",
    "        def __init__(self, d_model, heads):\n",
    "            super(DecoderLayer, self).__init__()\n",
    "\n",
    "            self.self_multihead = MultiHeadAttention(heads, d_model)\n",
    "            self.src_multihead = MultiHeadAttention(heads, d_model)\n",
    "            self.feed_forward = FeedForward(d_model)\n",
    "            self.layerNorm = nn.LayerNorm(d_model)\n",
    "            self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        \n",
    "        def forward(self, embedding, encoded_repr, src_mask, target_mask):\n",
    "            \n",
    "            query = self.dropout(self.self_multihead(embedding, embedding, embedding, target_mask))\n",
    "            query = self.layerNorm(query + embedding)\n",
    "            \n",
    "            interacted = self.dropout(self.src_multihead(query, encoded_repr, encoded_repr, src_mask))\n",
    "            interacted = self.layerNorm(interacted + query)\n",
    "            \n",
    "            feed_forward_out = self.dropout(self.feed_forward(interacted))\n",
    "            \n",
    "            decoded = self.layerNorm(feed_forward_out + interacted)\n",
    "            \n",
    "            return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0a1cd215",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, heads, n_layers, word_map):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.vocab_size = len(word_map)\n",
    "        self.embeddings = Embeddings(self.vocab_size, d_model)\n",
    "        \n",
    "        self.encoder = nn.ModuleList([EncoderLayer(d_model, heads) for _ in range(n_layers)])\n",
    "        self.decoder = nn.ModuleList([DecoderLayer(d_model, heads) for _ in range(n_layers)])\n",
    "        \n",
    "        self.logit = nn.Linear(self.d_model, self.vocab_size)\n",
    "        \n",
    "    \n",
    "    def encode(self, src_words, src_mask):\n",
    "        src_embeddings = self.embeddings(src_words)\n",
    "        \n",
    "        for layer in self.encoder:\n",
    "            src_embeddings = layer(src_embeddings, src_mask)\n",
    "        \n",
    "        return src_embeddings\n",
    "    \n",
    "    \n",
    "    def decode(self, target_words, target_mask, src_embeddings, src_mask):\n",
    "        tgt_embeddings = self.embeddings(target_words)\n",
    "        \n",
    "        for layer in self.decoder:\n",
    "            tgt_embeddings = layer(tgt_embeddings, src_embeddings, src_mask, target_mask)\n",
    "            \n",
    "        return tgt_embeddings\n",
    "    \n",
    "    \n",
    "    def forward(self, src_words, src_mask, target_words, target_mask):\n",
    "        \n",
    "        encoded = self.encode(src_words=src_words, src_mask=src_mask)\n",
    "        decoded = self.decode(target_words, target_mask, encoded, src_mask)\n",
    "        \n",
    "        out = nn.functional.log_softmax(self.logit(decoded))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3c4ed9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdamWarmup:\n",
    "    \n",
    "    def __init__(self, model_size, warmup_steps, optimizer):\n",
    "        \n",
    "        self.model_size = model_size\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        self.current_step = 0\n",
    "        self.lr = 0\n",
    "        \n",
    "    def get_lr(self):\n",
    "        return self.model_size ** (-0.5) * \\\n",
    "            min(self.current_step ** (-0.5), self.current_step * self.warmup_steps ** (-1.5))\n",
    "    \n",
    "    \n",
    "    def step(self):\n",
    "        self.current_step += 1\n",
    "        lr = self.get_lr()\n",
    "        \n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        self.lr = lr\n",
    "        \n",
    "        #update weights\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "764dd065",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoseWithLS(nn.Module):\n",
    "    \n",
    "    def __init__(self, size, smooth):\n",
    "        super(LoseWithLS, self).__init__()\n",
    "        \n",
    "        self.criterion = nn.KLDivLoss(size_average=False, reduce=False)\n",
    "        self.smooth = smooth\n",
    "        self.confidence = 1.0 - smooth\n",
    "        self.size = size\n",
    "        \n",
    "    \n",
    "    def forward(self, prediction, target, mask):\n",
    "        \n",
    "        #prediction: (batch_size, max_words, vocab_size)\n",
    "        prediction = prediction.view(-1, prediction.size(-1))\n",
    "        target = target.contiguous().view(-1)\n",
    "        mask = mask.float()\n",
    "        mask = mask.view(-1)\n",
    "        \n",
    "        labels = prediction.data.clone()\n",
    "        labels.fill_(self.smooth / (self.size - 1))\n",
    "        labels.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        \n",
    "        loss = self.criterion(prediction, labels) #(batch_size * max_words, vocab_size)\n",
    "        loss = (loss.sum(1) * mask).sum() / mask.sum()\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "255ddd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512\n",
    "heads=8\n",
    "n_layers = 1\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "epochs = 1\n",
    "warmup_steps = 4000\n",
    "\n",
    "with open('../data/WORDMAP_corpus.json', 'r') as f:\n",
    "    word_map = json.load(f)\n",
    "\n",
    "transformer = Transformer(d_model, heads, n_layers, word_map)\n",
    "transformer.to(device)\n",
    "\n",
    "adam_optimizer = torch.optim.Adam(transformer.parameters(), lr=0, betas=(0.9, 0.98), eps= 1e-9)\n",
    "transformer_optimizer = AdamWarmup(d_model, warmup_steps, adam_optimizer)\n",
    "criterion = LoseWithLS(size=len(word_map), smooth=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "87e0584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, transformer, transformer_optimizer, criterion, epoch, print_every):\n",
    "    \n",
    "    transformer.train()\n",
    "    sum_loss = 0\n",
    "    count = 0\n",
    "    \n",
    "    for i, (question, reply) in enumerate(train_loader):\n",
    "        \n",
    "        samples = question.shape[0]\n",
    "        \n",
    "        question = question.to(device)\n",
    "        reply = reply.to(device)\n",
    "        \n",
    "        #sentence: <start> I went home today <end>\n",
    "        #reply_input: <start> I went home today\n",
    "        #reply_target: I went home today <end>\n",
    "        reply_input = reply[:, :-1]\n",
    "        reply_target = reply[:, 1:]\n",
    "        \n",
    "        question_mask, reply_input_mask, reply_target_mask = create_masks(question, reply_input, reply_target)\n",
    "        \n",
    "        #run through transformer\n",
    "        out = transformer(question, question_mask, reply_input, reply_input_mask)\n",
    "        loss = criterion(out, reply_target, reply_target_mask)\n",
    "        \n",
    "        #backprop\n",
    "        transformer_optimizer.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        transformer_optimizer.step()\n",
    "        \n",
    "        #loss accumlation\n",
    "        sum_loss += loss * samples\n",
    "        count += samples\n",
    "        \n",
    "        if i % print_every == 0:\n",
    "            print('Epoch: [{}][{}/{}]\\t Loss: {:.3f}'.format(epoch, i, len(train_loader), sum_loss / count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0403ba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(transformer, question, question_mask, max_len, word_map):\n",
    "    \n",
    "    rev_word_map = {v:k for k, v in word_map.items()}\n",
    "    \n",
    "    transformer.eval()\n",
    "    \n",
    "    start_token = word_map['<start>']\n",
    "    encoded = transformer.encode(question, question_mask)\n",
    "    words = torch.LongTensor([[start_token]]).to(device)\n",
    "    \n",
    "    for step in range(max_len - 1):\n",
    "        \n",
    "        size = words.shape[0]\n",
    "        target_mask = torch.triu(torch.ones(size, size)).transpose(0, 1).type(dtype=torch.uint8)\n",
    "        target_mask = target_mask.to(device).unsqueeze(0)\n",
    "        \n",
    "        decoded = transformer.deocde(words, target_mask, encoded, question_mask) #(1,1,vocab_size)\n",
    "        \n",
    "        preds = transformer.logit(decoded[:, -1]) #(1, vocab_size)\n",
    "        \n",
    "        _, next_word = torch.max(pred, dim = 1) #(1,1)\n",
    "        \n",
    "        if next_word == word_map['<end>']:\n",
    "            break\n",
    "        words = torch.cat([words, torch.LongTensor([[next_word]]).to(device)], dim=1)\n",
    "        \n",
    "    words = words.squeeze(0)\n",
    "    words = words.tolist()\n",
    "    \n",
    "    sen_idx = [w for w in words if w not in {word_map['<start>']}]\n",
    "    sentence = ' '.join([rev_word_map[sen_idx[k]] for k in range(len(sen_idx))])\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e01c28ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fm/r4mdm1_n5s5c4cvws96yn7qm0000gn/T/ipykernel_29542/3855806577.py:39: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = nn.functional.log_softmax(self.logit(decoded))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/2217]\t Loss: 1.189\n",
      "Epoch: [0][1/2217]\t Loss: 1.191\n",
      "Epoch: [0][2/2217]\t Loss: 1.187\n",
      "Epoch: [0][3/2217]\t Loss: 1.190\n",
      "Epoch: [0][4/2217]\t Loss: 1.191\n",
      "Epoch: [0][5/2217]\t Loss: 1.187\n",
      "Epoch: [0][6/2217]\t Loss: 1.186\n",
      "Epoch: [0][7/2217]\t Loss: 1.186\n",
      "Epoch: [0][8/2217]\t Loss: 1.186\n",
      "Epoch: [0][9/2217]\t Loss: 1.186\n",
      "Epoch: [0][10/2217]\t Loss: 1.186\n",
      "Epoch: [0][11/2217]\t Loss: 1.185\n",
      "Epoch: [0][12/2217]\t Loss: 1.186\n",
      "Epoch: [0][13/2217]\t Loss: 1.186\n",
      "Epoch: [0][14/2217]\t Loss: 1.187\n",
      "Epoch: [0][15/2217]\t Loss: 1.186\n",
      "Epoch: [0][16/2217]\t Loss: 1.186\n",
      "Epoch: [0][17/2217]\t Loss: 1.185\n",
      "Epoch: [0][18/2217]\t Loss: 1.184\n",
      "Epoch: [0][19/2217]\t Loss: 1.184\n",
      "Epoch: [0][20/2217]\t Loss: 1.183\n",
      "Epoch: [0][21/2217]\t Loss: 1.183\n",
      "Epoch: [0][22/2217]\t Loss: 1.182\n",
      "Epoch: [0][23/2217]\t Loss: 1.181\n",
      "Epoch: [0][24/2217]\t Loss: 1.181\n",
      "Epoch: [0][25/2217]\t Loss: 1.181\n",
      "Epoch: [0][26/2217]\t Loss: 1.180\n",
      "Epoch: [0][27/2217]\t Loss: 1.179\n",
      "Epoch: [0][28/2217]\t Loss: 1.178\n",
      "Epoch: [0][29/2217]\t Loss: 1.177\n",
      "Epoch: [0][30/2217]\t Loss: 1.176\n",
      "Epoch: [0][31/2217]\t Loss: 1.175\n",
      "Epoch: [0][32/2217]\t Loss: 1.174\n",
      "Epoch: [0][33/2217]\t Loss: 1.174\n",
      "Epoch: [0][34/2217]\t Loss: 1.173\n",
      "Epoch: [0][35/2217]\t Loss: 1.173\n",
      "Epoch: [0][36/2217]\t Loss: 1.172\n",
      "Epoch: [0][37/2217]\t Loss: 1.172\n",
      "Epoch: [0][38/2217]\t Loss: 1.171\n",
      "Epoch: [0][39/2217]\t Loss: 1.171\n",
      "Epoch: [0][40/2217]\t Loss: 1.170\n",
      "Epoch: [0][41/2217]\t Loss: 1.170\n",
      "Epoch: [0][42/2217]\t Loss: 1.169\n",
      "Epoch: [0][43/2217]\t Loss: 1.168\n",
      "Epoch: [0][44/2217]\t Loss: 1.168\n",
      "Epoch: [0][45/2217]\t Loss: 1.168\n",
      "Epoch: [0][46/2217]\t Loss: 1.167\n",
      "Epoch: [0][47/2217]\t Loss: 1.166\n",
      "Epoch: [0][48/2217]\t Loss: 1.165\n",
      "Epoch: [0][49/2217]\t Loss: 1.164\n",
      "Epoch: [0][50/2217]\t Loss: 1.163\n",
      "Epoch: [0][51/2217]\t Loss: 1.163\n",
      "Epoch: [0][52/2217]\t Loss: 1.162\n",
      "Epoch: [0][53/2217]\t Loss: 1.161\n",
      "Epoch: [0][54/2217]\t Loss: 1.161\n",
      "Epoch: [0][55/2217]\t Loss: 1.160\n",
      "Epoch: [0][56/2217]\t Loss: 1.159\n",
      "Epoch: [0][57/2217]\t Loss: 1.158\n",
      "Epoch: [0][58/2217]\t Loss: 1.157\n",
      "Epoch: [0][59/2217]\t Loss: 1.156\n",
      "Epoch: [0][60/2217]\t Loss: 1.155\n",
      "Epoch: [0][61/2217]\t Loss: 1.154\n",
      "Epoch: [0][62/2217]\t Loss: 1.153\n",
      "Epoch: [0][63/2217]\t Loss: 1.152\n",
      "Epoch: [0][64/2217]\t Loss: 1.152\n",
      "Epoch: [0][65/2217]\t Loss: 1.150\n",
      "Epoch: [0][66/2217]\t Loss: 1.149\n",
      "Epoch: [0][67/2217]\t Loss: 1.148\n",
      "Epoch: [0][68/2217]\t Loss: 1.147\n",
      "Epoch: [0][69/2217]\t Loss: 1.146\n",
      "Epoch: [0][70/2217]\t Loss: 1.145\n",
      "Epoch: [0][71/2217]\t Loss: 1.144\n",
      "Epoch: [0][72/2217]\t Loss: 1.143\n",
      "Epoch: [0][73/2217]\t Loss: 1.142\n",
      "Epoch: [0][74/2217]\t Loss: 1.141\n",
      "Epoch: [0][75/2217]\t Loss: 1.140\n",
      "Epoch: [0][76/2217]\t Loss: 1.139\n",
      "Epoch: [0][77/2217]\t Loss: 1.138\n",
      "Epoch: [0][78/2217]\t Loss: 1.137\n",
      "Epoch: [0][79/2217]\t Loss: 1.136\n",
      "Epoch: [0][80/2217]\t Loss: 1.135\n",
      "Epoch: [0][81/2217]\t Loss: 1.133\n",
      "Epoch: [0][82/2217]\t Loss: 1.132\n",
      "Epoch: [0][83/2217]\t Loss: 1.131\n",
      "Epoch: [0][84/2217]\t Loss: 1.130\n",
      "Epoch: [0][85/2217]\t Loss: 1.130\n",
      "Epoch: [0][86/2217]\t Loss: 1.129\n",
      "Epoch: [0][87/2217]\t Loss: 1.128\n",
      "Epoch: [0][88/2217]\t Loss: 1.127\n",
      "Epoch: [0][89/2217]\t Loss: 1.126\n",
      "Epoch: [0][90/2217]\t Loss: 1.125\n",
      "Epoch: [0][91/2217]\t Loss: 1.124\n",
      "Epoch: [0][92/2217]\t Loss: 1.123\n",
      "Epoch: [0][93/2217]\t Loss: 1.122\n",
      "Epoch: [0][94/2217]\t Loss: 1.121\n",
      "Epoch: [0][95/2217]\t Loss: 1.120\n",
      "Epoch: [0][96/2217]\t Loss: 1.119\n",
      "Epoch: [0][97/2217]\t Loss: 1.118\n",
      "Epoch: [0][98/2217]\t Loss: 1.117\n",
      "Epoch: [0][99/2217]\t Loss: 1.116\n",
      "Epoch: [0][100/2217]\t Loss: 1.115\n",
      "Epoch: [0][101/2217]\t Loss: 1.114\n",
      "Epoch: [0][102/2217]\t Loss: 1.112\n",
      "Epoch: [0][103/2217]\t Loss: 1.111\n",
      "Epoch: [0][104/2217]\t Loss: 1.110\n",
      "Epoch: [0][105/2217]\t Loss: 1.109\n",
      "Epoch: [0][106/2217]\t Loss: 1.108\n",
      "Epoch: [0][107/2217]\t Loss: 1.107\n",
      "Epoch: [0][108/2217]\t Loss: 1.106\n",
      "Epoch: [0][109/2217]\t Loss: 1.105\n",
      "Epoch: [0][110/2217]\t Loss: 1.104\n",
      "Epoch: [0][111/2217]\t Loss: 1.102\n",
      "Epoch: [0][112/2217]\t Loss: 1.101\n",
      "Epoch: [0][113/2217]\t Loss: 1.100\n",
      "Epoch: [0][114/2217]\t Loss: 1.099\n",
      "Epoch: [0][115/2217]\t Loss: 1.098\n",
      "Epoch: [0][116/2217]\t Loss: 1.097\n",
      "Epoch: [0][117/2217]\t Loss: 1.096\n",
      "Epoch: [0][118/2217]\t Loss: 1.095\n",
      "Epoch: [0][119/2217]\t Loss: 1.093\n",
      "Epoch: [0][120/2217]\t Loss: 1.092\n",
      "Epoch: [0][121/2217]\t Loss: 1.091\n",
      "Epoch: [0][122/2217]\t Loss: 1.090\n",
      "Epoch: [0][123/2217]\t Loss: 1.089\n",
      "Epoch: [0][124/2217]\t Loss: 1.088\n",
      "Epoch: [0][125/2217]\t Loss: 1.087\n",
      "Epoch: [0][126/2217]\t Loss: 1.086\n",
      "Epoch: [0][127/2217]\t Loss: 1.085\n",
      "Epoch: [0][128/2217]\t Loss: 1.084\n",
      "Epoch: [0][129/2217]\t Loss: 1.082\n",
      "Epoch: [0][130/2217]\t Loss: 1.081\n",
      "Epoch: [0][131/2217]\t Loss: 1.080\n",
      "Epoch: [0][132/2217]\t Loss: 1.079\n",
      "Epoch: [0][133/2217]\t Loss: 1.078\n",
      "Epoch: [0][134/2217]\t Loss: 1.077\n",
      "Epoch: [0][135/2217]\t Loss: 1.076\n",
      "Epoch: [0][136/2217]\t Loss: 1.074\n",
      "Epoch: [0][137/2217]\t Loss: 1.073\n",
      "Epoch: [0][138/2217]\t Loss: 1.072\n",
      "Epoch: [0][139/2217]\t Loss: 1.071\n",
      "Epoch: [0][140/2217]\t Loss: 1.070\n",
      "Epoch: [0][141/2217]\t Loss: 1.069\n",
      "Epoch: [0][142/2217]\t Loss: 1.068\n",
      "Epoch: [0][143/2217]\t Loss: 1.067\n",
      "Epoch: [0][144/2217]\t Loss: 1.065\n",
      "Epoch: [0][145/2217]\t Loss: 1.064\n",
      "Epoch: [0][146/2217]\t Loss: 1.063\n",
      "Epoch: [0][147/2217]\t Loss: 1.062\n",
      "Epoch: [0][148/2217]\t Loss: 1.060\n",
      "Epoch: [0][149/2217]\t Loss: 1.059\n",
      "Epoch: [0][150/2217]\t Loss: 1.058\n",
      "Epoch: [0][151/2217]\t Loss: 1.056\n",
      "Epoch: [0][152/2217]\t Loss: 1.055\n",
      "Epoch: [0][153/2217]\t Loss: 1.053\n",
      "Epoch: [0][154/2217]\t Loss: 1.052\n",
      "Epoch: [0][155/2217]\t Loss: 1.051\n",
      "Epoch: [0][156/2217]\t Loss: 1.050\n",
      "Epoch: [0][157/2217]\t Loss: 1.048\n",
      "Epoch: [0][158/2217]\t Loss: 1.047\n",
      "Epoch: [0][159/2217]\t Loss: 1.046\n",
      "Epoch: [0][160/2217]\t Loss: 1.045\n",
      "Epoch: [0][161/2217]\t Loss: 1.044\n",
      "Epoch: [0][162/2217]\t Loss: 1.042\n",
      "Epoch: [0][163/2217]\t Loss: 1.041\n",
      "Epoch: [0][164/2217]\t Loss: 1.040\n",
      "Epoch: [0][165/2217]\t Loss: 1.038\n",
      "Epoch: [0][166/2217]\t Loss: 1.037\n",
      "Epoch: [0][167/2217]\t Loss: 1.036\n",
      "Epoch: [0][168/2217]\t Loss: 1.034\n",
      "Epoch: [0][169/2217]\t Loss: 1.033\n",
      "Epoch: [0][170/2217]\t Loss: 1.032\n",
      "Epoch: [0][171/2217]\t Loss: 1.030\n",
      "Epoch: [0][172/2217]\t Loss: 1.029\n",
      "Epoch: [0][173/2217]\t Loss: 1.028\n",
      "Epoch: [0][174/2217]\t Loss: 1.026\n",
      "Epoch: [0][175/2217]\t Loss: 1.025\n",
      "Epoch: [0][176/2217]\t Loss: 1.024\n",
      "Epoch: [0][177/2217]\t Loss: 1.022\n",
      "Epoch: [0][178/2217]\t Loss: 1.021\n",
      "Epoch: [0][179/2217]\t Loss: 1.020\n",
      "Epoch: [0][180/2217]\t Loss: 1.018\n",
      "Epoch: [0][181/2217]\t Loss: 1.017\n",
      "Epoch: [0][182/2217]\t Loss: 1.016\n",
      "Epoch: [0][183/2217]\t Loss: 1.014\n",
      "Epoch: [0][184/2217]\t Loss: 1.013\n",
      "Epoch: [0][185/2217]\t Loss: 1.012\n",
      "Epoch: [0][186/2217]\t Loss: 1.010\n",
      "Epoch: [0][187/2217]\t Loss: 1.009\n",
      "Epoch: [0][188/2217]\t Loss: 1.007\n",
      "Epoch: [0][189/2217]\t Loss: 1.006\n",
      "Epoch: [0][190/2217]\t Loss: 1.005\n",
      "Epoch: [0][191/2217]\t Loss: 1.003\n",
      "Epoch: [0][192/2217]\t Loss: 1.002\n",
      "Epoch: [0][193/2217]\t Loss: 1.001\n",
      "Epoch: [0][194/2217]\t Loss: 0.999\n",
      "Epoch: [0][195/2217]\t Loss: 0.998\n",
      "Epoch: [0][196/2217]\t Loss: 0.996\n",
      "Epoch: [0][197/2217]\t Loss: 0.995\n",
      "Epoch: [0][198/2217]\t Loss: 0.994\n",
      "Epoch: [0][199/2217]\t Loss: 0.992\n",
      "Epoch: [0][200/2217]\t Loss: 0.991\n",
      "Epoch: [0][201/2217]\t Loss: 0.989\n",
      "Epoch: [0][202/2217]\t Loss: 0.988\n",
      "Epoch: [0][203/2217]\t Loss: 0.986\n",
      "Epoch: [0][204/2217]\t Loss: 0.985\n",
      "Epoch: [0][205/2217]\t Loss: 0.983\n",
      "Epoch: [0][206/2217]\t Loss: 0.982\n",
      "Epoch: [0][207/2217]\t Loss: 0.981\n",
      "Epoch: [0][208/2217]\t Loss: 0.979\n",
      "Epoch: [0][209/2217]\t Loss: 0.978\n",
      "Epoch: [0][210/2217]\t Loss: 0.976\n",
      "Epoch: [0][211/2217]\t Loss: 0.975\n",
      "Epoch: [0][212/2217]\t Loss: 0.974\n",
      "Epoch: [0][213/2217]\t Loss: 0.972\n",
      "Epoch: [0][214/2217]\t Loss: 0.971\n",
      "Epoch: [0][215/2217]\t Loss: 0.969\n",
      "Epoch: [0][216/2217]\t Loss: 0.968\n",
      "Epoch: [0][217/2217]\t Loss: 0.967\n",
      "Epoch: [0][218/2217]\t Loss: 0.965\n",
      "Epoch: [0][219/2217]\t Loss: 0.964\n",
      "Epoch: [0][220/2217]\t Loss: 0.962\n",
      "Epoch: [0][221/2217]\t Loss: 0.960\n",
      "Epoch: [0][222/2217]\t Loss: 0.959\n",
      "Epoch: [0][223/2217]\t Loss: 0.958\n",
      "Epoch: [0][224/2217]\t Loss: 0.957\n",
      "Epoch: [0][225/2217]\t Loss: 0.955\n",
      "Epoch: [0][226/2217]\t Loss: 0.954\n",
      "Epoch: [0][227/2217]\t Loss: 0.952\n",
      "Epoch: [0][228/2217]\t Loss: 0.951\n",
      "Epoch: [0][229/2217]\t Loss: 0.949\n",
      "Epoch: [0][230/2217]\t Loss: 0.948\n",
      "Epoch: [0][231/2217]\t Loss: 0.947\n",
      "Epoch: [0][232/2217]\t Loss: 0.945\n",
      "Epoch: [0][233/2217]\t Loss: 0.944\n",
      "Epoch: [0][234/2217]\t Loss: 0.943\n",
      "Epoch: [0][235/2217]\t Loss: 0.941\n",
      "Epoch: [0][236/2217]\t Loss: 0.940\n",
      "Epoch: [0][237/2217]\t Loss: 0.938\n",
      "Epoch: [0][238/2217]\t Loss: 0.937\n",
      "Epoch: [0][239/2217]\t Loss: 0.936\n",
      "Epoch: [0][240/2217]\t Loss: 0.934\n",
      "Epoch: [0][241/2217]\t Loss: 0.933\n",
      "Epoch: [0][242/2217]\t Loss: 0.931\n",
      "Epoch: [0][243/2217]\t Loss: 0.930\n",
      "Epoch: [0][244/2217]\t Loss: 0.928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][245/2217]\t Loss: 0.927\n",
      "Epoch: [0][246/2217]\t Loss: 0.926\n",
      "Epoch: [0][247/2217]\t Loss: 0.924\n",
      "Epoch: [0][248/2217]\t Loss: 0.923\n",
      "Epoch: [0][249/2217]\t Loss: 0.922\n",
      "Epoch: [0][250/2217]\t Loss: 0.920\n",
      "Epoch: [0][251/2217]\t Loss: 0.919\n",
      "Epoch: [0][252/2217]\t Loss: 0.917\n",
      "Epoch: [0][253/2217]\t Loss: 0.916\n",
      "Epoch: [0][254/2217]\t Loss: 0.914\n",
      "Epoch: [0][255/2217]\t Loss: 0.913\n",
      "Epoch: [0][256/2217]\t Loss: 0.911\n",
      "Epoch: [0][257/2217]\t Loss: 0.910\n",
      "Epoch: [0][258/2217]\t Loss: 0.909\n",
      "Epoch: [0][259/2217]\t Loss: 0.907\n",
      "Epoch: [0][260/2217]\t Loss: 0.906\n",
      "Epoch: [0][261/2217]\t Loss: 0.904\n",
      "Epoch: [0][262/2217]\t Loss: 0.903\n",
      "Epoch: [0][263/2217]\t Loss: 0.901\n",
      "Epoch: [0][264/2217]\t Loss: 0.900\n",
      "Epoch: [0][265/2217]\t Loss: 0.898\n",
      "Epoch: [0][266/2217]\t Loss: 0.897\n",
      "Epoch: [0][267/2217]\t Loss: 0.896\n",
      "Epoch: [0][268/2217]\t Loss: 0.894\n",
      "Epoch: [0][269/2217]\t Loss: 0.893\n",
      "Epoch: [0][270/2217]\t Loss: 0.891\n",
      "Epoch: [0][271/2217]\t Loss: 0.890\n",
      "Epoch: [0][272/2217]\t Loss: 0.889\n",
      "Epoch: [0][273/2217]\t Loss: 0.887\n",
      "Epoch: [0][274/2217]\t Loss: 0.886\n",
      "Epoch: [0][275/2217]\t Loss: 0.885\n",
      "Epoch: [0][276/2217]\t Loss: 0.883\n",
      "Epoch: [0][277/2217]\t Loss: 0.882\n",
      "Epoch: [0][278/2217]\t Loss: 0.881\n",
      "Epoch: [0][279/2217]\t Loss: 0.880\n",
      "Epoch: [0][280/2217]\t Loss: 0.878\n",
      "Epoch: [0][281/2217]\t Loss: 0.877\n",
      "Epoch: [0][282/2217]\t Loss: 0.875\n",
      "Epoch: [0][283/2217]\t Loss: 0.874\n",
      "Epoch: [0][284/2217]\t Loss: 0.873\n",
      "Epoch: [0][285/2217]\t Loss: 0.871\n",
      "Epoch: [0][286/2217]\t Loss: 0.870\n",
      "Epoch: [0][287/2217]\t Loss: 0.868\n",
      "Epoch: [0][288/2217]\t Loss: 0.867\n",
      "Epoch: [0][289/2217]\t Loss: 0.866\n",
      "Epoch: [0][290/2217]\t Loss: 0.865\n",
      "Epoch: [0][291/2217]\t Loss: 0.864\n",
      "Epoch: [0][292/2217]\t Loss: 0.862\n",
      "Epoch: [0][293/2217]\t Loss: 0.861\n",
      "Epoch: [0][294/2217]\t Loss: 0.860\n",
      "Epoch: [0][295/2217]\t Loss: 0.859\n",
      "Epoch: [0][296/2217]\t Loss: 0.858\n",
      "Epoch: [0][297/2217]\t Loss: 0.856\n",
      "Epoch: [0][298/2217]\t Loss: 0.855\n",
      "Epoch: [0][299/2217]\t Loss: 0.854\n",
      "Epoch: [0][300/2217]\t Loss: 0.852\n",
      "Epoch: [0][301/2217]\t Loss: 0.851\n",
      "Epoch: [0][302/2217]\t Loss: 0.850\n",
      "Epoch: [0][303/2217]\t Loss: 0.849\n",
      "Epoch: [0][304/2217]\t Loss: 0.847\n",
      "Epoch: [0][305/2217]\t Loss: 0.846\n",
      "Epoch: [0][306/2217]\t Loss: 0.845\n",
      "Epoch: [0][307/2217]\t Loss: 0.843\n",
      "Epoch: [0][308/2217]\t Loss: 0.842\n",
      "Epoch: [0][309/2217]\t Loss: 0.841\n",
      "Epoch: [0][310/2217]\t Loss: 0.839\n",
      "Epoch: [0][311/2217]\t Loss: 0.838\n",
      "Epoch: [0][312/2217]\t Loss: 0.837\n",
      "Epoch: [0][313/2217]\t Loss: 0.836\n",
      "Epoch: [0][314/2217]\t Loss: 0.835\n",
      "Epoch: [0][315/2217]\t Loss: 0.833\n",
      "Epoch: [0][316/2217]\t Loss: 0.832\n",
      "Epoch: [0][317/2217]\t Loss: 0.831\n",
      "Epoch: [0][318/2217]\t Loss: 0.829\n",
      "Epoch: [0][319/2217]\t Loss: 0.828\n",
      "Epoch: [0][320/2217]\t Loss: 0.827\n",
      "Epoch: [0][321/2217]\t Loss: 0.826\n",
      "Epoch: [0][322/2217]\t Loss: 0.824\n",
      "Epoch: [0][323/2217]\t Loss: 0.823\n",
      "Epoch: [0][324/2217]\t Loss: 0.822\n",
      "Epoch: [0][325/2217]\t Loss: 0.821\n",
      "Epoch: [0][326/2217]\t Loss: 0.819\n",
      "Epoch: [0][327/2217]\t Loss: 0.818\n",
      "Epoch: [0][328/2217]\t Loss: 0.817\n",
      "Epoch: [0][329/2217]\t Loss: 0.816\n",
      "Epoch: [0][330/2217]\t Loss: 0.814\n",
      "Epoch: [0][331/2217]\t Loss: 0.813\n",
      "Epoch: [0][332/2217]\t Loss: 0.812\n",
      "Epoch: [0][333/2217]\t Loss: 0.811\n",
      "Epoch: [0][334/2217]\t Loss: 0.810\n",
      "Epoch: [0][335/2217]\t Loss: 0.808\n",
      "Epoch: [0][336/2217]\t Loss: 0.807\n",
      "Epoch: [0][337/2217]\t Loss: 0.806\n",
      "Epoch: [0][338/2217]\t Loss: 0.805\n",
      "Epoch: [0][339/2217]\t Loss: 0.803\n",
      "Epoch: [0][340/2217]\t Loss: 0.802\n",
      "Epoch: [0][341/2217]\t Loss: 0.801\n",
      "Epoch: [0][342/2217]\t Loss: 0.800\n",
      "Epoch: [0][343/2217]\t Loss: 0.799\n",
      "Epoch: [0][344/2217]\t Loss: 0.798\n",
      "Epoch: [0][345/2217]\t Loss: 0.796\n",
      "Epoch: [0][346/2217]\t Loss: 0.795\n",
      "Epoch: [0][347/2217]\t Loss: 0.794\n",
      "Epoch: [0][348/2217]\t Loss: 0.793\n",
      "Epoch: [0][349/2217]\t Loss: 0.792\n",
      "Epoch: [0][350/2217]\t Loss: 0.791\n",
      "Epoch: [0][351/2217]\t Loss: 0.790\n",
      "Epoch: [0][352/2217]\t Loss: 0.788\n",
      "Epoch: [0][353/2217]\t Loss: 0.787\n",
      "Epoch: [0][354/2217]\t Loss: 0.786\n",
      "Epoch: [0][355/2217]\t Loss: 0.785\n",
      "Epoch: [0][356/2217]\t Loss: 0.784\n",
      "Epoch: [0][357/2217]\t Loss: 0.783\n",
      "Epoch: [0][358/2217]\t Loss: 0.782\n",
      "Epoch: [0][359/2217]\t Loss: 0.780\n",
      "Epoch: [0][360/2217]\t Loss: 0.779\n",
      "Epoch: [0][361/2217]\t Loss: 0.778\n",
      "Epoch: [0][362/2217]\t Loss: 0.777\n",
      "Epoch: [0][363/2217]\t Loss: 0.776\n",
      "Epoch: [0][364/2217]\t Loss: 0.775\n",
      "Epoch: [0][365/2217]\t Loss: 0.773\n",
      "Epoch: [0][366/2217]\t Loss: 0.772\n",
      "Epoch: [0][367/2217]\t Loss: 0.771\n",
      "Epoch: [0][368/2217]\t Loss: 0.770\n",
      "Epoch: [0][369/2217]\t Loss: 0.769\n",
      "Epoch: [0][370/2217]\t Loss: 0.768\n",
      "Epoch: [0][371/2217]\t Loss: 0.767\n",
      "Epoch: [0][372/2217]\t Loss: 0.766\n",
      "Epoch: [0][373/2217]\t Loss: 0.765\n",
      "Epoch: [0][374/2217]\t Loss: 0.764\n",
      "Epoch: [0][375/2217]\t Loss: 0.763\n",
      "Epoch: [0][376/2217]\t Loss: 0.762\n",
      "Epoch: [0][377/2217]\t Loss: 0.761\n",
      "Epoch: [0][378/2217]\t Loss: 0.760\n",
      "Epoch: [0][379/2217]\t Loss: 0.759\n",
      "Epoch: [0][380/2217]\t Loss: 0.757\n",
      "Epoch: [0][381/2217]\t Loss: 0.756\n",
      "Epoch: [0][382/2217]\t Loss: 0.755\n",
      "Epoch: [0][383/2217]\t Loss: 0.754\n",
      "Epoch: [0][384/2217]\t Loss: 0.753\n",
      "Epoch: [0][385/2217]\t Loss: 0.752\n",
      "Epoch: [0][386/2217]\t Loss: 0.751\n",
      "Epoch: [0][387/2217]\t Loss: 0.750\n",
      "Epoch: [0][388/2217]\t Loss: 0.749\n",
      "Epoch: [0][389/2217]\t Loss: 0.748\n",
      "Epoch: [0][390/2217]\t Loss: 0.746\n",
      "Epoch: [0][391/2217]\t Loss: 0.745\n",
      "Epoch: [0][392/2217]\t Loss: 0.744\n",
      "Epoch: [0][393/2217]\t Loss: 0.743\n",
      "Epoch: [0][394/2217]\t Loss: 0.742\n",
      "Epoch: [0][395/2217]\t Loss: 0.741\n",
      "Epoch: [0][396/2217]\t Loss: 0.740\n",
      "Epoch: [0][397/2217]\t Loss: 0.739\n",
      "Epoch: [0][398/2217]\t Loss: 0.738\n",
      "Epoch: [0][399/2217]\t Loss: 0.737\n",
      "Epoch: [0][400/2217]\t Loss: 0.736\n",
      "Epoch: [0][401/2217]\t Loss: 0.734\n",
      "Epoch: [0][402/2217]\t Loss: 0.733\n",
      "Epoch: [0][403/2217]\t Loss: 0.732\n",
      "Epoch: [0][404/2217]\t Loss: 0.731\n",
      "Epoch: [0][405/2217]\t Loss: 0.730\n",
      "Epoch: [0][406/2217]\t Loss: 0.729\n",
      "Epoch: [0][407/2217]\t Loss: 0.728\n",
      "Epoch: [0][408/2217]\t Loss: 0.727\n",
      "Epoch: [0][409/2217]\t Loss: 0.726\n",
      "Epoch: [0][410/2217]\t Loss: 0.725\n",
      "Epoch: [0][411/2217]\t Loss: 0.724\n",
      "Epoch: [0][412/2217]\t Loss: 0.723\n",
      "Epoch: [0][413/2217]\t Loss: 0.722\n",
      "Epoch: [0][414/2217]\t Loss: 0.721\n",
      "Epoch: [0][415/2217]\t Loss: 0.720\n",
      "Epoch: [0][416/2217]\t Loss: 0.719\n",
      "Epoch: [0][417/2217]\t Loss: 0.718\n",
      "Epoch: [0][418/2217]\t Loss: 0.717\n",
      "Epoch: [0][419/2217]\t Loss: 0.716\n",
      "Epoch: [0][420/2217]\t Loss: 0.715\n",
      "Epoch: [0][421/2217]\t Loss: 0.714\n",
      "Epoch: [0][422/2217]\t Loss: 0.714\n",
      "Epoch: [0][423/2217]\t Loss: 0.713\n",
      "Epoch: [0][424/2217]\t Loss: 0.711\n",
      "Epoch: [0][425/2217]\t Loss: 0.710\n",
      "Epoch: [0][426/2217]\t Loss: 0.710\n",
      "Epoch: [0][427/2217]\t Loss: 0.709\n",
      "Epoch: [0][428/2217]\t Loss: 0.708\n",
      "Epoch: [0][429/2217]\t Loss: 0.707\n",
      "Epoch: [0][430/2217]\t Loss: 0.706\n",
      "Epoch: [0][431/2217]\t Loss: 0.704\n",
      "Epoch: [0][432/2217]\t Loss: 0.704\n",
      "Epoch: [0][433/2217]\t Loss: 0.703\n",
      "Epoch: [0][434/2217]\t Loss: 0.702\n",
      "Epoch: [0][435/2217]\t Loss: 0.701\n",
      "Epoch: [0][436/2217]\t Loss: 0.700\n",
      "Epoch: [0][437/2217]\t Loss: 0.699\n",
      "Epoch: [0][438/2217]\t Loss: 0.698\n",
      "Epoch: [0][439/2217]\t Loss: 0.697\n",
      "Epoch: [0][440/2217]\t Loss: 0.696\n",
      "Epoch: [0][441/2217]\t Loss: 0.695\n",
      "Epoch: [0][442/2217]\t Loss: 0.694\n",
      "Epoch: [0][443/2217]\t Loss: 0.693\n",
      "Epoch: [0][444/2217]\t Loss: 0.692\n",
      "Epoch: [0][445/2217]\t Loss: 0.691\n",
      "Epoch: [0][446/2217]\t Loss: 0.690\n",
      "Epoch: [0][447/2217]\t Loss: 0.689\n",
      "Epoch: [0][448/2217]\t Loss: 0.688\n",
      "Epoch: [0][449/2217]\t Loss: 0.688\n",
      "Epoch: [0][450/2217]\t Loss: 0.687\n",
      "Epoch: [0][451/2217]\t Loss: 0.686\n",
      "Epoch: [0][452/2217]\t Loss: 0.685\n",
      "Epoch: [0][453/2217]\t Loss: 0.684\n",
      "Epoch: [0][454/2217]\t Loss: 0.683\n",
      "Epoch: [0][455/2217]\t Loss: 0.682\n",
      "Epoch: [0][456/2217]\t Loss: 0.681\n",
      "Epoch: [0][457/2217]\t Loss: 0.680\n",
      "Epoch: [0][458/2217]\t Loss: 0.680\n",
      "Epoch: [0][459/2217]\t Loss: 0.679\n",
      "Epoch: [0][460/2217]\t Loss: 0.678\n",
      "Epoch: [0][461/2217]\t Loss: 0.677\n",
      "Epoch: [0][462/2217]\t Loss: 0.676\n",
      "Epoch: [0][463/2217]\t Loss: 0.675\n",
      "Epoch: [0][464/2217]\t Loss: 0.674\n",
      "Epoch: [0][465/2217]\t Loss: 0.673\n",
      "Epoch: [0][466/2217]\t Loss: 0.673\n",
      "Epoch: [0][467/2217]\t Loss: 0.672\n",
      "Epoch: [0][468/2217]\t Loss: 0.671\n",
      "Epoch: [0][469/2217]\t Loss: 0.670\n",
      "Epoch: [0][470/2217]\t Loss: 0.669\n",
      "Epoch: [0][471/2217]\t Loss: 0.668\n",
      "Epoch: [0][472/2217]\t Loss: 0.667\n",
      "Epoch: [0][473/2217]\t Loss: 0.666\n",
      "Epoch: [0][474/2217]\t Loss: 0.666\n",
      "Epoch: [0][475/2217]\t Loss: 0.665\n",
      "Epoch: [0][476/2217]\t Loss: 0.664\n",
      "Epoch: [0][477/2217]\t Loss: 0.663\n",
      "Epoch: [0][478/2217]\t Loss: 0.662\n",
      "Epoch: [0][479/2217]\t Loss: 0.661\n",
      "Epoch: [0][480/2217]\t Loss: 0.660\n",
      "Epoch: [0][481/2217]\t Loss: 0.659\n",
      "Epoch: [0][482/2217]\t Loss: 0.659\n",
      "Epoch: [0][483/2217]\t Loss: 0.658\n",
      "Epoch: [0][484/2217]\t Loss: 0.657\n",
      "Epoch: [0][485/2217]\t Loss: 0.656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][486/2217]\t Loss: 0.655\n",
      "Epoch: [0][487/2217]\t Loss: 0.655\n",
      "Epoch: [0][488/2217]\t Loss: 0.654\n",
      "Epoch: [0][489/2217]\t Loss: 0.653\n",
      "Epoch: [0][490/2217]\t Loss: 0.652\n",
      "Epoch: [0][491/2217]\t Loss: 0.651\n",
      "Epoch: [0][492/2217]\t Loss: 0.650\n",
      "Epoch: [0][493/2217]\t Loss: 0.649\n",
      "Epoch: [0][494/2217]\t Loss: 0.649\n",
      "Epoch: [0][495/2217]\t Loss: 0.648\n",
      "Epoch: [0][496/2217]\t Loss: 0.647\n",
      "Epoch: [0][497/2217]\t Loss: 0.646\n",
      "Epoch: [0][498/2217]\t Loss: 0.645\n",
      "Epoch: [0][499/2217]\t Loss: 0.644\n",
      "Epoch: [0][500/2217]\t Loss: 0.644\n",
      "Epoch: [0][501/2217]\t Loss: 0.643\n",
      "Epoch: [0][502/2217]\t Loss: 0.642\n",
      "Epoch: [0][503/2217]\t Loss: 0.641\n",
      "Epoch: [0][504/2217]\t Loss: 0.640\n",
      "Epoch: [0][505/2217]\t Loss: 0.640\n",
      "Epoch: [0][506/2217]\t Loss: 0.639\n",
      "Epoch: [0][507/2217]\t Loss: 0.638\n",
      "Epoch: [0][508/2217]\t Loss: 0.637\n",
      "Epoch: [0][509/2217]\t Loss: 0.636\n",
      "Epoch: [0][510/2217]\t Loss: 0.635\n",
      "Epoch: [0][511/2217]\t Loss: 0.635\n",
      "Epoch: [0][512/2217]\t Loss: 0.634\n",
      "Epoch: [0][513/2217]\t Loss: 0.633\n",
      "Epoch: [0][514/2217]\t Loss: 0.632\n",
      "Epoch: [0][515/2217]\t Loss: 0.631\n",
      "Epoch: [0][516/2217]\t Loss: 0.630\n",
      "Epoch: [0][517/2217]\t Loss: 0.630\n",
      "Epoch: [0][518/2217]\t Loss: 0.629\n",
      "Epoch: [0][519/2217]\t Loss: 0.628\n",
      "Epoch: [0][520/2217]\t Loss: 0.627\n",
      "Epoch: [0][521/2217]\t Loss: 0.626\n",
      "Epoch: [0][522/2217]\t Loss: 0.626\n",
      "Epoch: [0][523/2217]\t Loss: 0.625\n",
      "Epoch: [0][524/2217]\t Loss: 0.624\n",
      "Epoch: [0][525/2217]\t Loss: 0.624\n",
      "Epoch: [0][526/2217]\t Loss: 0.623\n",
      "Epoch: [0][527/2217]\t Loss: 0.622\n",
      "Epoch: [0][528/2217]\t Loss: 0.621\n",
      "Epoch: [0][529/2217]\t Loss: 0.620\n",
      "Epoch: [0][530/2217]\t Loss: 0.620\n",
      "Epoch: [0][531/2217]\t Loss: 0.619\n",
      "Epoch: [0][532/2217]\t Loss: 0.618\n",
      "Epoch: [0][533/2217]\t Loss: 0.618\n",
      "Epoch: [0][534/2217]\t Loss: 0.617\n",
      "Epoch: [0][535/2217]\t Loss: 0.616\n",
      "Epoch: [0][536/2217]\t Loss: 0.615\n",
      "Epoch: [0][537/2217]\t Loss: 0.615\n",
      "Epoch: [0][538/2217]\t Loss: 0.614\n",
      "Epoch: [0][539/2217]\t Loss: 0.613\n",
      "Epoch: [0][540/2217]\t Loss: 0.612\n",
      "Epoch: [0][541/2217]\t Loss: 0.612\n",
      "Epoch: [0][542/2217]\t Loss: 0.611\n",
      "Epoch: [0][543/2217]\t Loss: 0.610\n",
      "Epoch: [0][544/2217]\t Loss: 0.609\n",
      "Epoch: [0][545/2217]\t Loss: 0.608\n",
      "Epoch: [0][546/2217]\t Loss: 0.608\n",
      "Epoch: [0][547/2217]\t Loss: 0.607\n",
      "Epoch: [0][548/2217]\t Loss: 0.606\n",
      "Epoch: [0][549/2217]\t Loss: 0.605\n",
      "Epoch: [0][550/2217]\t Loss: 0.605\n",
      "Epoch: [0][551/2217]\t Loss: 0.604\n",
      "Epoch: [0][552/2217]\t Loss: 0.603\n",
      "Epoch: [0][553/2217]\t Loss: 0.602\n",
      "Epoch: [0][554/2217]\t Loss: 0.601\n",
      "Epoch: [0][555/2217]\t Loss: 0.601\n",
      "Epoch: [0][556/2217]\t Loss: 0.600\n",
      "Epoch: [0][557/2217]\t Loss: 0.599\n",
      "Epoch: [0][558/2217]\t Loss: 0.598\n",
      "Epoch: [0][559/2217]\t Loss: 0.598\n",
      "Epoch: [0][560/2217]\t Loss: 0.597\n",
      "Epoch: [0][561/2217]\t Loss: 0.596\n",
      "Epoch: [0][562/2217]\t Loss: 0.596\n",
      "Epoch: [0][563/2217]\t Loss: 0.595\n",
      "Epoch: [0][564/2217]\t Loss: 0.594\n",
      "Epoch: [0][565/2217]\t Loss: 0.594\n",
      "Epoch: [0][566/2217]\t Loss: 0.593\n",
      "Epoch: [0][567/2217]\t Loss: 0.592\n",
      "Epoch: [0][568/2217]\t Loss: 0.591\n",
      "Epoch: [0][569/2217]\t Loss: 0.591\n",
      "Epoch: [0][570/2217]\t Loss: 0.590\n",
      "Epoch: [0][571/2217]\t Loss: 0.589\n",
      "Epoch: [0][572/2217]\t Loss: 0.588\n",
      "Epoch: [0][573/2217]\t Loss: 0.588\n",
      "Epoch: [0][574/2217]\t Loss: 0.587\n",
      "Epoch: [0][575/2217]\t Loss: 0.586\n",
      "Epoch: [0][576/2217]\t Loss: 0.586\n",
      "Epoch: [0][577/2217]\t Loss: 0.585\n",
      "Epoch: [0][578/2217]\t Loss: 0.584\n",
      "Epoch: [0][579/2217]\t Loss: 0.584\n",
      "Epoch: [0][580/2217]\t Loss: 0.583\n",
      "Epoch: [0][581/2217]\t Loss: 0.582\n",
      "Epoch: [0][582/2217]\t Loss: 0.582\n",
      "Epoch: [0][583/2217]\t Loss: 0.581\n",
      "Epoch: [0][584/2217]\t Loss: 0.580\n",
      "Epoch: [0][585/2217]\t Loss: 0.580\n",
      "Epoch: [0][586/2217]\t Loss: 0.579\n",
      "Epoch: [0][587/2217]\t Loss: 0.578\n",
      "Epoch: [0][588/2217]\t Loss: 0.578\n",
      "Epoch: [0][589/2217]\t Loss: 0.577\n",
      "Epoch: [0][590/2217]\t Loss: 0.576\n",
      "Epoch: [0][591/2217]\t Loss: 0.575\n",
      "Epoch: [0][592/2217]\t Loss: 0.575\n",
      "Epoch: [0][593/2217]\t Loss: 0.574\n",
      "Epoch: [0][594/2217]\t Loss: 0.573\n",
      "Epoch: [0][595/2217]\t Loss: 0.573\n",
      "Epoch: [0][596/2217]\t Loss: 0.572\n",
      "Epoch: [0][597/2217]\t Loss: 0.571\n",
      "Epoch: [0][598/2217]\t Loss: 0.571\n",
      "Epoch: [0][599/2217]\t Loss: 0.570\n",
      "Epoch: [0][600/2217]\t Loss: 0.569\n",
      "Epoch: [0][601/2217]\t Loss: 0.569\n",
      "Epoch: [0][602/2217]\t Loss: 0.568\n",
      "Epoch: [0][603/2217]\t Loss: 0.567\n",
      "Epoch: [0][604/2217]\t Loss: 0.567\n",
      "Epoch: [0][605/2217]\t Loss: 0.566\n",
      "Epoch: [0][606/2217]\t Loss: 0.565\n",
      "Epoch: [0][607/2217]\t Loss: 0.565\n",
      "Epoch: [0][608/2217]\t Loss: 0.564\n",
      "Epoch: [0][609/2217]\t Loss: 0.563\n",
      "Epoch: [0][610/2217]\t Loss: 0.563\n",
      "Epoch: [0][611/2217]\t Loss: 0.562\n",
      "Epoch: [0][612/2217]\t Loss: 0.561\n",
      "Epoch: [0][613/2217]\t Loss: 0.561\n",
      "Epoch: [0][614/2217]\t Loss: 0.560\n",
      "Epoch: [0][615/2217]\t Loss: 0.559\n",
      "Epoch: [0][616/2217]\t Loss: 0.559\n",
      "Epoch: [0][617/2217]\t Loss: 0.558\n",
      "Epoch: [0][618/2217]\t Loss: 0.558\n",
      "Epoch: [0][619/2217]\t Loss: 0.557\n",
      "Epoch: [0][620/2217]\t Loss: 0.556\n",
      "Epoch: [0][621/2217]\t Loss: 0.555\n",
      "Epoch: [0][622/2217]\t Loss: 0.555\n",
      "Epoch: [0][623/2217]\t Loss: 0.554\n",
      "Epoch: [0][624/2217]\t Loss: 0.553\n",
      "Epoch: [0][625/2217]\t Loss: 0.553\n",
      "Epoch: [0][626/2217]\t Loss: 0.552\n",
      "Epoch: [0][627/2217]\t Loss: 0.551\n",
      "Epoch: [0][628/2217]\t Loss: 0.551\n",
      "Epoch: [0][629/2217]\t Loss: 0.550\n",
      "Epoch: [0][630/2217]\t Loss: 0.550\n",
      "Epoch: [0][631/2217]\t Loss: 0.549\n",
      "Epoch: [0][632/2217]\t Loss: 0.548\n",
      "Epoch: [0][633/2217]\t Loss: 0.548\n",
      "Epoch: [0][634/2217]\t Loss: 0.547\n",
      "Epoch: [0][635/2217]\t Loss: 0.546\n",
      "Epoch: [0][636/2217]\t Loss: 0.546\n",
      "Epoch: [0][637/2217]\t Loss: 0.545\n",
      "Epoch: [0][638/2217]\t Loss: 0.545\n",
      "Epoch: [0][639/2217]\t Loss: 0.544\n",
      "Epoch: [0][640/2217]\t Loss: 0.543\n",
      "Epoch: [0][641/2217]\t Loss: 0.543\n",
      "Epoch: [0][642/2217]\t Loss: 0.542\n",
      "Epoch: [0][643/2217]\t Loss: 0.542\n",
      "Epoch: [0][644/2217]\t Loss: 0.541\n",
      "Epoch: [0][645/2217]\t Loss: 0.540\n",
      "Epoch: [0][646/2217]\t Loss: 0.540\n",
      "Epoch: [0][647/2217]\t Loss: 0.539\n",
      "Epoch: [0][648/2217]\t Loss: 0.538\n",
      "Epoch: [0][649/2217]\t Loss: 0.538\n",
      "Epoch: [0][650/2217]\t Loss: 0.537\n",
      "Epoch: [0][651/2217]\t Loss: 0.536\n",
      "Epoch: [0][652/2217]\t Loss: 0.536\n",
      "Epoch: [0][653/2217]\t Loss: 0.535\n",
      "Epoch: [0][654/2217]\t Loss: 0.534\n",
      "Epoch: [0][655/2217]\t Loss: 0.534\n",
      "Epoch: [0][656/2217]\t Loss: 0.533\n",
      "Epoch: [0][657/2217]\t Loss: 0.533\n",
      "Epoch: [0][658/2217]\t Loss: 0.532\n",
      "Epoch: [0][659/2217]\t Loss: 0.531\n",
      "Epoch: [0][660/2217]\t Loss: 0.531\n",
      "Epoch: [0][661/2217]\t Loss: 0.530\n",
      "Epoch: [0][662/2217]\t Loss: 0.530\n",
      "Epoch: [0][663/2217]\t Loss: 0.529\n",
      "Epoch: [0][664/2217]\t Loss: 0.528\n",
      "Epoch: [0][665/2217]\t Loss: 0.528\n",
      "Epoch: [0][666/2217]\t Loss: 0.527\n",
      "Epoch: [0][667/2217]\t Loss: 0.527\n",
      "Epoch: [0][668/2217]\t Loss: 0.526\n",
      "Epoch: [0][669/2217]\t Loss: 0.525\n",
      "Epoch: [0][670/2217]\t Loss: 0.525\n",
      "Epoch: [0][671/2217]\t Loss: 0.524\n",
      "Epoch: [0][672/2217]\t Loss: 0.523\n",
      "Epoch: [0][673/2217]\t Loss: 0.523\n",
      "Epoch: [0][674/2217]\t Loss: 0.522\n",
      "Epoch: [0][675/2217]\t Loss: 0.522\n",
      "Epoch: [0][676/2217]\t Loss: 0.521\n",
      "Epoch: [0][677/2217]\t Loss: 0.520\n",
      "Epoch: [0][678/2217]\t Loss: 0.520\n",
      "Epoch: [0][679/2217]\t Loss: 0.519\n",
      "Epoch: [0][680/2217]\t Loss: 0.519\n",
      "Epoch: [0][681/2217]\t Loss: 0.518\n",
      "Epoch: [0][682/2217]\t Loss: 0.517\n",
      "Epoch: [0][683/2217]\t Loss: 0.517\n",
      "Epoch: [0][684/2217]\t Loss: 0.516\n",
      "Epoch: [0][685/2217]\t Loss: 0.516\n",
      "Epoch: [0][686/2217]\t Loss: 0.515\n",
      "Epoch: [0][687/2217]\t Loss: 0.515\n",
      "Epoch: [0][688/2217]\t Loss: 0.514\n",
      "Epoch: [0][689/2217]\t Loss: 0.513\n",
      "Epoch: [0][690/2217]\t Loss: 0.513\n",
      "Epoch: [0][691/2217]\t Loss: 0.512\n",
      "Epoch: [0][692/2217]\t Loss: 0.512\n",
      "Epoch: [0][693/2217]\t Loss: 0.511\n",
      "Epoch: [0][694/2217]\t Loss: 0.511\n",
      "Epoch: [0][695/2217]\t Loss: 0.510\n",
      "Epoch: [0][696/2217]\t Loss: 0.509\n",
      "Epoch: [0][697/2217]\t Loss: 0.509\n",
      "Epoch: [0][698/2217]\t Loss: 0.508\n",
      "Epoch: [0][699/2217]\t Loss: 0.508\n",
      "Epoch: [0][700/2217]\t Loss: 0.507\n",
      "Epoch: [0][701/2217]\t Loss: 0.507\n",
      "Epoch: [0][702/2217]\t Loss: 0.506\n",
      "Epoch: [0][703/2217]\t Loss: 0.506\n",
      "Epoch: [0][704/2217]\t Loss: 0.505\n",
      "Epoch: [0][705/2217]\t Loss: 0.504\n",
      "Epoch: [0][706/2217]\t Loss: 0.504\n",
      "Epoch: [0][707/2217]\t Loss: 0.503\n",
      "Epoch: [0][708/2217]\t Loss: 0.503\n",
      "Epoch: [0][709/2217]\t Loss: 0.502\n",
      "Epoch: [0][710/2217]\t Loss: 0.502\n",
      "Epoch: [0][711/2217]\t Loss: 0.501\n",
      "Epoch: [0][712/2217]\t Loss: 0.500\n",
      "Epoch: [0][713/2217]\t Loss: 0.500\n",
      "Epoch: [0][714/2217]\t Loss: 0.499\n",
      "Epoch: [0][715/2217]\t Loss: 0.499\n",
      "Epoch: [0][716/2217]\t Loss: 0.498\n",
      "Epoch: [0][717/2217]\t Loss: 0.498\n",
      "Epoch: [0][718/2217]\t Loss: 0.497\n",
      "Epoch: [0][719/2217]\t Loss: 0.497\n",
      "Epoch: [0][720/2217]\t Loss: 0.496\n",
      "Epoch: [0][721/2217]\t Loss: 0.496\n",
      "Epoch: [0][722/2217]\t Loss: 0.495\n",
      "Epoch: [0][723/2217]\t Loss: 0.495\n",
      "Epoch: [0][724/2217]\t Loss: 0.494\n",
      "Epoch: [0][725/2217]\t Loss: 0.494\n",
      "Epoch: [0][726/2217]\t Loss: 0.493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][727/2217]\t Loss: 0.492\n",
      "Epoch: [0][728/2217]\t Loss: 0.492\n",
      "Epoch: [0][729/2217]\t Loss: 0.491\n",
      "Epoch: [0][730/2217]\t Loss: 0.491\n",
      "Epoch: [0][731/2217]\t Loss: 0.490\n",
      "Epoch: [0][732/2217]\t Loss: 0.490\n",
      "Epoch: [0][733/2217]\t Loss: 0.489\n",
      "Epoch: [0][734/2217]\t Loss: 0.489\n",
      "Epoch: [0][735/2217]\t Loss: 0.488\n",
      "Epoch: [0][736/2217]\t Loss: 0.488\n",
      "Epoch: [0][737/2217]\t Loss: 0.487\n",
      "Epoch: [0][738/2217]\t Loss: 0.487\n",
      "Epoch: [0][739/2217]\t Loss: 0.486\n",
      "Epoch: [0][740/2217]\t Loss: 0.486\n",
      "Epoch: [0][741/2217]\t Loss: 0.485\n",
      "Epoch: [0][742/2217]\t Loss: 0.484\n",
      "Epoch: [0][743/2217]\t Loss: 0.484\n",
      "Epoch: [0][744/2217]\t Loss: 0.483\n",
      "Epoch: [0][745/2217]\t Loss: 0.483\n",
      "Epoch: [0][746/2217]\t Loss: 0.482\n",
      "Epoch: [0][747/2217]\t Loss: 0.482\n",
      "Epoch: [0][748/2217]\t Loss: 0.481\n",
      "Epoch: [0][749/2217]\t Loss: 0.481\n",
      "Epoch: [0][750/2217]\t Loss: 0.480\n",
      "Epoch: [0][751/2217]\t Loss: 0.480\n",
      "Epoch: [0][752/2217]\t Loss: 0.479\n",
      "Epoch: [0][753/2217]\t Loss: 0.479\n",
      "Epoch: [0][754/2217]\t Loss: 0.478\n",
      "Epoch: [0][755/2217]\t Loss: 0.478\n",
      "Epoch: [0][756/2217]\t Loss: 0.477\n",
      "Epoch: [0][757/2217]\t Loss: 0.477\n",
      "Epoch: [0][758/2217]\t Loss: 0.476\n",
      "Epoch: [0][759/2217]\t Loss: 0.475\n",
      "Epoch: [0][760/2217]\t Loss: 0.475\n",
      "Epoch: [0][761/2217]\t Loss: 0.474\n",
      "Epoch: [0][762/2217]\t Loss: 0.474\n",
      "Epoch: [0][763/2217]\t Loss: 0.473\n",
      "Epoch: [0][764/2217]\t Loss: 0.473\n",
      "Epoch: [0][765/2217]\t Loss: 0.472\n",
      "Epoch: [0][766/2217]\t Loss: 0.472\n",
      "Epoch: [0][767/2217]\t Loss: 0.471\n",
      "Epoch: [0][768/2217]\t Loss: 0.471\n",
      "Epoch: [0][769/2217]\t Loss: 0.470\n",
      "Epoch: [0][770/2217]\t Loss: 0.470\n",
      "Epoch: [0][771/2217]\t Loss: 0.469\n",
      "Epoch: [0][772/2217]\t Loss: 0.469\n",
      "Epoch: [0][773/2217]\t Loss: 0.468\n",
      "Epoch: [0][774/2217]\t Loss: 0.468\n",
      "Epoch: [0][775/2217]\t Loss: 0.467\n",
      "Epoch: [0][776/2217]\t Loss: 0.467\n",
      "Epoch: [0][777/2217]\t Loss: 0.466\n",
      "Epoch: [0][778/2217]\t Loss: 0.466\n",
      "Epoch: [0][779/2217]\t Loss: 0.465\n",
      "Epoch: [0][780/2217]\t Loss: 0.465\n",
      "Epoch: [0][781/2217]\t Loss: 0.464\n",
      "Epoch: [0][782/2217]\t Loss: 0.464\n",
      "Epoch: [0][783/2217]\t Loss: 0.463\n",
      "Epoch: [0][784/2217]\t Loss: 0.463\n",
      "Epoch: [0][785/2217]\t Loss: 0.462\n",
      "Epoch: [0][786/2217]\t Loss: 0.462\n",
      "Epoch: [0][787/2217]\t Loss: 0.461\n",
      "Epoch: [0][788/2217]\t Loss: 0.461\n",
      "Epoch: [0][789/2217]\t Loss: 0.460\n",
      "Epoch: [0][790/2217]\t Loss: 0.460\n",
      "Epoch: [0][791/2217]\t Loss: 0.459\n",
      "Epoch: [0][792/2217]\t Loss: 0.459\n",
      "Epoch: [0][793/2217]\t Loss: 0.458\n",
      "Epoch: [0][794/2217]\t Loss: 0.458\n",
      "Epoch: [0][795/2217]\t Loss: 0.458\n",
      "Epoch: [0][796/2217]\t Loss: 0.457\n",
      "Epoch: [0][797/2217]\t Loss: 0.456\n",
      "Epoch: [0][798/2217]\t Loss: 0.456\n",
      "Epoch: [0][799/2217]\t Loss: 0.455\n",
      "Epoch: [0][800/2217]\t Loss: 0.455\n",
      "Epoch: [0][801/2217]\t Loss: 0.454\n",
      "Epoch: [0][802/2217]\t Loss: 0.454\n",
      "Epoch: [0][803/2217]\t Loss: 0.453\n",
      "Epoch: [0][804/2217]\t Loss: 0.453\n",
      "Epoch: [0][805/2217]\t Loss: 0.452\n",
      "Epoch: [0][806/2217]\t Loss: 0.452\n",
      "Epoch: [0][807/2217]\t Loss: 0.451\n",
      "Epoch: [0][808/2217]\t Loss: 0.451\n",
      "Epoch: [0][809/2217]\t Loss: 0.450\n",
      "Epoch: [0][810/2217]\t Loss: 0.450\n",
      "Epoch: [0][811/2217]\t Loss: 0.449\n",
      "Epoch: [0][812/2217]\t Loss: 0.449\n",
      "Epoch: [0][813/2217]\t Loss: 0.448\n",
      "Epoch: [0][814/2217]\t Loss: 0.448\n",
      "Epoch: [0][815/2217]\t Loss: 0.447\n",
      "Epoch: [0][816/2217]\t Loss: 0.446\n",
      "Epoch: [0][817/2217]\t Loss: 0.446\n",
      "Epoch: [0][818/2217]\t Loss: 0.445\n",
      "Epoch: [0][819/2217]\t Loss: 0.445\n",
      "Epoch: [0][820/2217]\t Loss: 0.445\n",
      "Epoch: [0][821/2217]\t Loss: 0.444\n",
      "Epoch: [0][822/2217]\t Loss: 0.444\n",
      "Epoch: [0][823/2217]\t Loss: 0.443\n",
      "Epoch: [0][824/2217]\t Loss: 0.443\n",
      "Epoch: [0][825/2217]\t Loss: 0.442\n",
      "Epoch: [0][826/2217]\t Loss: 0.442\n",
      "Epoch: [0][827/2217]\t Loss: 0.442\n",
      "Epoch: [0][828/2217]\t Loss: 0.441\n",
      "Epoch: [0][829/2217]\t Loss: 0.441\n",
      "Epoch: [0][830/2217]\t Loss: 0.440\n",
      "Epoch: [0][831/2217]\t Loss: 0.440\n",
      "Epoch: [0][832/2217]\t Loss: 0.439\n",
      "Epoch: [0][833/2217]\t Loss: 0.439\n",
      "Epoch: [0][834/2217]\t Loss: 0.438\n",
      "Epoch: [0][835/2217]\t Loss: 0.438\n",
      "Epoch: [0][836/2217]\t Loss: 0.438\n",
      "Epoch: [0][837/2217]\t Loss: 0.437\n",
      "Epoch: [0][838/2217]\t Loss: 0.437\n",
      "Epoch: [0][839/2217]\t Loss: 0.436\n",
      "Epoch: [0][840/2217]\t Loss: 0.436\n",
      "Epoch: [0][841/2217]\t Loss: 0.435\n",
      "Epoch: [0][842/2217]\t Loss: 0.435\n",
      "Epoch: [0][843/2217]\t Loss: 0.435\n",
      "Epoch: [0][844/2217]\t Loss: 0.434\n",
      "Epoch: [0][845/2217]\t Loss: 0.434\n",
      "Epoch: [0][846/2217]\t Loss: 0.433\n",
      "Epoch: [0][847/2217]\t Loss: 0.433\n",
      "Epoch: [0][848/2217]\t Loss: 0.432\n",
      "Epoch: [0][849/2217]\t Loss: 0.432\n",
      "Epoch: [0][850/2217]\t Loss: 0.432\n",
      "Epoch: [0][851/2217]\t Loss: 0.431\n",
      "Epoch: [0][852/2217]\t Loss: 0.431\n",
      "Epoch: [0][853/2217]\t Loss: 0.430\n",
      "Epoch: [0][854/2217]\t Loss: 0.430\n",
      "Epoch: [0][855/2217]\t Loss: 0.429\n",
      "Epoch: [0][856/2217]\t Loss: 0.429\n",
      "Epoch: [0][857/2217]\t Loss: 0.429\n",
      "Epoch: [0][858/2217]\t Loss: 0.428\n",
      "Epoch: [0][859/2217]\t Loss: 0.428\n",
      "Epoch: [0][860/2217]\t Loss: 0.427\n",
      "Epoch: [0][861/2217]\t Loss: 0.427\n",
      "Epoch: [0][862/2217]\t Loss: 0.426\n",
      "Epoch: [0][863/2217]\t Loss: 0.426\n",
      "Epoch: [0][864/2217]\t Loss: 0.425\n",
      "Epoch: [0][865/2217]\t Loss: 0.425\n",
      "Epoch: [0][866/2217]\t Loss: 0.424\n",
      "Epoch: [0][867/2217]\t Loss: 0.424\n",
      "Epoch: [0][868/2217]\t Loss: 0.423\n",
      "Epoch: [0][869/2217]\t Loss: 0.423\n",
      "Epoch: [0][870/2217]\t Loss: 0.423\n",
      "Epoch: [0][871/2217]\t Loss: 0.422\n",
      "Epoch: [0][872/2217]\t Loss: 0.422\n",
      "Epoch: [0][873/2217]\t Loss: 0.421\n",
      "Epoch: [0][874/2217]\t Loss: 0.421\n",
      "Epoch: [0][875/2217]\t Loss: 0.420\n",
      "Epoch: [0][876/2217]\t Loss: 0.420\n",
      "Epoch: [0][877/2217]\t Loss: 0.419\n",
      "Epoch: [0][878/2217]\t Loss: 0.419\n",
      "Epoch: [0][879/2217]\t Loss: 0.418\n",
      "Epoch: [0][880/2217]\t Loss: 0.418\n",
      "Epoch: [0][881/2217]\t Loss: 0.418\n",
      "Epoch: [0][882/2217]\t Loss: 0.417\n",
      "Epoch: [0][883/2217]\t Loss: 0.417\n",
      "Epoch: [0][884/2217]\t Loss: 0.416\n",
      "Epoch: [0][885/2217]\t Loss: 0.416\n",
      "Epoch: [0][886/2217]\t Loss: 0.415\n",
      "Epoch: [0][887/2217]\t Loss: 0.415\n",
      "Epoch: [0][888/2217]\t Loss: 0.414\n",
      "Epoch: [0][889/2217]\t Loss: 0.414\n",
      "Epoch: [0][890/2217]\t Loss: 0.413\n",
      "Epoch: [0][891/2217]\t Loss: 0.413\n",
      "Epoch: [0][892/2217]\t Loss: 0.413\n",
      "Epoch: [0][893/2217]\t Loss: 0.412\n",
      "Epoch: [0][894/2217]\t Loss: 0.412\n",
      "Epoch: [0][895/2217]\t Loss: 0.411\n",
      "Epoch: [0][896/2217]\t Loss: 0.411\n",
      "Epoch: [0][897/2217]\t Loss: 0.411\n",
      "Epoch: [0][898/2217]\t Loss: 0.410\n",
      "Epoch: [0][899/2217]\t Loss: 0.410\n",
      "Epoch: [0][900/2217]\t Loss: 0.409\n",
      "Epoch: [0][901/2217]\t Loss: 0.409\n",
      "Epoch: [0][902/2217]\t Loss: 0.409\n",
      "Epoch: [0][903/2217]\t Loss: 0.408\n",
      "Epoch: [0][904/2217]\t Loss: 0.408\n",
      "Epoch: [0][905/2217]\t Loss: 0.407\n",
      "Epoch: [0][906/2217]\t Loss: 0.407\n",
      "Epoch: [0][907/2217]\t Loss: 0.406\n",
      "Epoch: [0][908/2217]\t Loss: 0.406\n",
      "Epoch: [0][909/2217]\t Loss: 0.406\n",
      "Epoch: [0][910/2217]\t Loss: 0.405\n",
      "Epoch: [0][911/2217]\t Loss: 0.405\n",
      "Epoch: [0][912/2217]\t Loss: 0.404\n",
      "Epoch: [0][913/2217]\t Loss: 0.404\n",
      "Epoch: [0][914/2217]\t Loss: 0.403\n",
      "Epoch: [0][915/2217]\t Loss: 0.403\n",
      "Epoch: [0][916/2217]\t Loss: 0.402\n",
      "Epoch: [0][917/2217]\t Loss: 0.402\n",
      "Epoch: [0][918/2217]\t Loss: 0.402\n",
      "Epoch: [0][919/2217]\t Loss: 0.401\n",
      "Epoch: [0][920/2217]\t Loss: 0.401\n",
      "Epoch: [0][921/2217]\t Loss: 0.400\n",
      "Epoch: [0][922/2217]\t Loss: 0.400\n",
      "Epoch: [0][923/2217]\t Loss: 0.400\n",
      "Epoch: [0][924/2217]\t Loss: 0.399\n",
      "Epoch: [0][925/2217]\t Loss: 0.399\n",
      "Epoch: [0][926/2217]\t Loss: 0.398\n",
      "Epoch: [0][927/2217]\t Loss: 0.398\n",
      "Epoch: [0][928/2217]\t Loss: 0.398\n",
      "Epoch: [0][929/2217]\t Loss: 0.397\n",
      "Epoch: [0][930/2217]\t Loss: 0.397\n",
      "Epoch: [0][931/2217]\t Loss: 0.396\n",
      "Epoch: [0][932/2217]\t Loss: 0.396\n",
      "Epoch: [0][933/2217]\t Loss: 0.395\n",
      "Epoch: [0][934/2217]\t Loss: 0.395\n",
      "Epoch: [0][935/2217]\t Loss: 0.395\n",
      "Epoch: [0][936/2217]\t Loss: 0.394\n",
      "Epoch: [0][937/2217]\t Loss: 0.394\n",
      "Epoch: [0][938/2217]\t Loss: 0.394\n",
      "Epoch: [0][939/2217]\t Loss: 0.393\n",
      "Epoch: [0][940/2217]\t Loss: 0.393\n",
      "Epoch: [0][941/2217]\t Loss: 0.392\n",
      "Epoch: [0][942/2217]\t Loss: 0.392\n",
      "Epoch: [0][943/2217]\t Loss: 0.392\n",
      "Epoch: [0][944/2217]\t Loss: 0.391\n",
      "Epoch: [0][945/2217]\t Loss: 0.391\n",
      "Epoch: [0][946/2217]\t Loss: 0.390\n",
      "Epoch: [0][947/2217]\t Loss: 0.390\n",
      "Epoch: [0][948/2217]\t Loss: 0.390\n",
      "Epoch: [0][949/2217]\t Loss: 0.389\n",
      "Epoch: [0][950/2217]\t Loss: 0.389\n",
      "Epoch: [0][951/2217]\t Loss: 0.388\n",
      "Epoch: [0][952/2217]\t Loss: 0.388\n",
      "Epoch: [0][953/2217]\t Loss: 0.388\n",
      "Epoch: [0][954/2217]\t Loss: 0.387\n",
      "Epoch: [0][955/2217]\t Loss: 0.387\n",
      "Epoch: [0][956/2217]\t Loss: 0.387\n",
      "Epoch: [0][957/2217]\t Loss: 0.386\n",
      "Epoch: [0][958/2217]\t Loss: 0.386\n",
      "Epoch: [0][959/2217]\t Loss: 0.385\n",
      "Epoch: [0][960/2217]\t Loss: 0.385\n",
      "Epoch: [0][961/2217]\t Loss: 0.385\n",
      "Epoch: [0][962/2217]\t Loss: 0.384\n",
      "Epoch: [0][963/2217]\t Loss: 0.384\n",
      "Epoch: [0][964/2217]\t Loss: 0.384\n",
      "Epoch: [0][965/2217]\t Loss: 0.383\n",
      "Epoch: [0][966/2217]\t Loss: 0.383\n",
      "Epoch: [0][967/2217]\t Loss: 0.382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][968/2217]\t Loss: 0.382\n",
      "Epoch: [0][969/2217]\t Loss: 0.382\n",
      "Epoch: [0][970/2217]\t Loss: 0.381\n",
      "Epoch: [0][971/2217]\t Loss: 0.381\n",
      "Epoch: [0][972/2217]\t Loss: 0.381\n",
      "Epoch: [0][973/2217]\t Loss: 0.380\n",
      "Epoch: [0][974/2217]\t Loss: 0.380\n",
      "Epoch: [0][975/2217]\t Loss: 0.379\n",
      "Epoch: [0][976/2217]\t Loss: 0.379\n",
      "Epoch: [0][977/2217]\t Loss: 0.379\n",
      "Epoch: [0][978/2217]\t Loss: 0.378\n",
      "Epoch: [0][979/2217]\t Loss: 0.378\n",
      "Epoch: [0][980/2217]\t Loss: 0.378\n",
      "Epoch: [0][981/2217]\t Loss: 0.377\n",
      "Epoch: [0][982/2217]\t Loss: 0.377\n",
      "Epoch: [0][983/2217]\t Loss: 0.377\n",
      "Epoch: [0][984/2217]\t Loss: 0.376\n",
      "Epoch: [0][985/2217]\t Loss: 0.376\n",
      "Epoch: [0][986/2217]\t Loss: 0.375\n",
      "Epoch: [0][987/2217]\t Loss: 0.375\n",
      "Epoch: [0][988/2217]\t Loss: 0.375\n",
      "Epoch: [0][989/2217]\t Loss: 0.374\n",
      "Epoch: [0][990/2217]\t Loss: 0.374\n",
      "Epoch: [0][991/2217]\t Loss: 0.373\n",
      "Epoch: [0][992/2217]\t Loss: 0.373\n",
      "Epoch: [0][993/2217]\t Loss: 0.373\n",
      "Epoch: [0][994/2217]\t Loss: 0.372\n",
      "Epoch: [0][995/2217]\t Loss: 0.372\n",
      "Epoch: [0][996/2217]\t Loss: 0.372\n",
      "Epoch: [0][997/2217]\t Loss: 0.371\n",
      "Epoch: [0][998/2217]\t Loss: 0.371\n",
      "Epoch: [0][999/2217]\t Loss: 0.371\n",
      "Epoch: [0][1000/2217]\t Loss: 0.370\n",
      "Epoch: [0][1001/2217]\t Loss: 0.370\n",
      "Epoch: [0][1002/2217]\t Loss: 0.369\n",
      "Epoch: [0][1003/2217]\t Loss: 0.369\n",
      "Epoch: [0][1004/2217]\t Loss: 0.369\n",
      "Epoch: [0][1005/2217]\t Loss: 0.368\n",
      "Epoch: [0][1006/2217]\t Loss: 0.368\n",
      "Epoch: [0][1007/2217]\t Loss: 0.368\n",
      "Epoch: [0][1008/2217]\t Loss: 0.367\n",
      "Epoch: [0][1009/2217]\t Loss: 0.367\n",
      "Epoch: [0][1010/2217]\t Loss: 0.367\n",
      "Epoch: [0][1011/2217]\t Loss: 0.366\n",
      "Epoch: [0][1012/2217]\t Loss: 0.366\n",
      "Epoch: [0][1013/2217]\t Loss: 0.366\n",
      "Epoch: [0][1014/2217]\t Loss: 0.365\n",
      "Epoch: [0][1015/2217]\t Loss: 0.365\n",
      "Epoch: [0][1016/2217]\t Loss: 0.365\n",
      "Epoch: [0][1017/2217]\t Loss: 0.364\n",
      "Epoch: [0][1018/2217]\t Loss: 0.364\n",
      "Epoch: [0][1019/2217]\t Loss: 0.364\n",
      "Epoch: [0][1020/2217]\t Loss: 0.363\n",
      "Epoch: [0][1021/2217]\t Loss: 0.363\n",
      "Epoch: [0][1022/2217]\t Loss: 0.363\n",
      "Epoch: [0][1023/2217]\t Loss: 0.362\n",
      "Epoch: [0][1024/2217]\t Loss: 0.362\n",
      "Epoch: [0][1025/2217]\t Loss: 0.361\n",
      "Epoch: [0][1026/2217]\t Loss: 0.361\n",
      "Epoch: [0][1027/2217]\t Loss: 0.361\n",
      "Epoch: [0][1028/2217]\t Loss: 0.360\n",
      "Epoch: [0][1029/2217]\t Loss: 0.360\n",
      "Epoch: [0][1030/2217]\t Loss: 0.359\n",
      "Epoch: [0][1031/2217]\t Loss: 0.359\n",
      "Epoch: [0][1032/2217]\t Loss: 0.359\n",
      "Epoch: [0][1033/2217]\t Loss: 0.358\n",
      "Epoch: [0][1034/2217]\t Loss: 0.358\n",
      "Epoch: [0][1035/2217]\t Loss: 0.357\n",
      "Epoch: [0][1036/2217]\t Loss: 0.357\n",
      "Epoch: [0][1037/2217]\t Loss: 0.357\n",
      "Epoch: [0][1038/2217]\t Loss: 0.357\n",
      "Epoch: [0][1039/2217]\t Loss: 0.356\n",
      "Epoch: [0][1040/2217]\t Loss: 0.356\n",
      "Epoch: [0][1041/2217]\t Loss: 0.356\n",
      "Epoch: [0][1042/2217]\t Loss: 0.355\n",
      "Epoch: [0][1043/2217]\t Loss: 0.355\n",
      "Epoch: [0][1044/2217]\t Loss: 0.355\n",
      "Epoch: [0][1045/2217]\t Loss: 0.354\n",
      "Epoch: [0][1046/2217]\t Loss: 0.354\n",
      "Epoch: [0][1047/2217]\t Loss: 0.354\n",
      "Epoch: [0][1048/2217]\t Loss: 0.353\n",
      "Epoch: [0][1049/2217]\t Loss: 0.353\n",
      "Epoch: [0][1050/2217]\t Loss: 0.353\n",
      "Epoch: [0][1051/2217]\t Loss: 0.352\n",
      "Epoch: [0][1052/2217]\t Loss: 0.352\n",
      "Epoch: [0][1053/2217]\t Loss: 0.352\n",
      "Epoch: [0][1054/2217]\t Loss: 0.351\n",
      "Epoch: [0][1055/2217]\t Loss: 0.351\n",
      "Epoch: [0][1056/2217]\t Loss: 0.351\n",
      "Epoch: [0][1057/2217]\t Loss: 0.350\n",
      "Epoch: [0][1058/2217]\t Loss: 0.350\n",
      "Epoch: [0][1059/2217]\t Loss: 0.350\n",
      "Epoch: [0][1060/2217]\t Loss: 0.349\n",
      "Epoch: [0][1061/2217]\t Loss: 0.349\n",
      "Epoch: [0][1062/2217]\t Loss: 0.349\n",
      "Epoch: [0][1063/2217]\t Loss: 0.349\n",
      "Epoch: [0][1064/2217]\t Loss: 0.348\n",
      "Epoch: [0][1065/2217]\t Loss: 0.348\n",
      "Epoch: [0][1066/2217]\t Loss: 0.347\n",
      "Epoch: [0][1067/2217]\t Loss: 0.347\n",
      "Epoch: [0][1068/2217]\t Loss: 0.347\n",
      "Epoch: [0][1069/2217]\t Loss: 0.347\n",
      "Epoch: [0][1070/2217]\t Loss: 0.346\n",
      "Epoch: [0][1071/2217]\t Loss: 0.346\n",
      "Epoch: [0][1072/2217]\t Loss: 0.345\n",
      "Epoch: [0][1073/2217]\t Loss: 0.345\n",
      "Epoch: [0][1074/2217]\t Loss: 0.345\n",
      "Epoch: [0][1075/2217]\t Loss: 0.344\n",
      "Epoch: [0][1076/2217]\t Loss: 0.344\n",
      "Epoch: [0][1077/2217]\t Loss: 0.344\n",
      "Epoch: [0][1078/2217]\t Loss: 0.343\n",
      "Epoch: [0][1079/2217]\t Loss: 0.343\n",
      "Epoch: [0][1080/2217]\t Loss: 0.343\n",
      "Epoch: [0][1081/2217]\t Loss: 0.342\n",
      "Epoch: [0][1082/2217]\t Loss: 0.342\n",
      "Epoch: [0][1083/2217]\t Loss: 0.342\n",
      "Epoch: [0][1084/2217]\t Loss: 0.341\n",
      "Epoch: [0][1085/2217]\t Loss: 0.341\n",
      "Epoch: [0][1086/2217]\t Loss: 0.341\n",
      "Epoch: [0][1087/2217]\t Loss: 0.340\n",
      "Epoch: [0][1088/2217]\t Loss: 0.340\n",
      "Epoch: [0][1089/2217]\t Loss: 0.340\n",
      "Epoch: [0][1090/2217]\t Loss: 0.340\n",
      "Epoch: [0][1091/2217]\t Loss: 0.339\n",
      "Epoch: [0][1092/2217]\t Loss: 0.339\n",
      "Epoch: [0][1093/2217]\t Loss: 0.339\n",
      "Epoch: [0][1094/2217]\t Loss: 0.338\n",
      "Epoch: [0][1095/2217]\t Loss: 0.338\n",
      "Epoch: [0][1096/2217]\t Loss: 0.338\n",
      "Epoch: [0][1097/2217]\t Loss: 0.337\n",
      "Epoch: [0][1098/2217]\t Loss: 0.337\n",
      "Epoch: [0][1099/2217]\t Loss: 0.337\n",
      "Epoch: [0][1100/2217]\t Loss: 0.336\n",
      "Epoch: [0][1101/2217]\t Loss: 0.336\n",
      "Epoch: [0][1102/2217]\t Loss: 0.336\n",
      "Epoch: [0][1103/2217]\t Loss: 0.335\n",
      "Epoch: [0][1104/2217]\t Loss: 0.335\n",
      "Epoch: [0][1105/2217]\t Loss: 0.335\n",
      "Epoch: [0][1106/2217]\t Loss: 0.334\n",
      "Epoch: [0][1107/2217]\t Loss: 0.334\n",
      "Epoch: [0][1108/2217]\t Loss: 0.334\n",
      "Epoch: [0][1109/2217]\t Loss: 0.334\n",
      "Epoch: [0][1110/2217]\t Loss: 0.333\n",
      "Epoch: [0][1111/2217]\t Loss: 0.333\n",
      "Epoch: [0][1112/2217]\t Loss: 0.332\n",
      "Epoch: [0][1113/2217]\t Loss: 0.332\n",
      "Epoch: [0][1114/2217]\t Loss: 0.332\n",
      "Epoch: [0][1115/2217]\t Loss: 0.332\n",
      "Epoch: [0][1116/2217]\t Loss: 0.331\n",
      "Epoch: [0][1117/2217]\t Loss: 0.331\n",
      "Epoch: [0][1118/2217]\t Loss: 0.331\n",
      "Epoch: [0][1119/2217]\t Loss: 0.330\n",
      "Epoch: [0][1120/2217]\t Loss: 0.330\n",
      "Epoch: [0][1121/2217]\t Loss: 0.330\n",
      "Epoch: [0][1122/2217]\t Loss: 0.329\n",
      "Epoch: [0][1123/2217]\t Loss: 0.329\n",
      "Epoch: [0][1124/2217]\t Loss: 0.329\n",
      "Epoch: [0][1125/2217]\t Loss: 0.328\n",
      "Epoch: [0][1126/2217]\t Loss: 0.328\n",
      "Epoch: [0][1127/2217]\t Loss: 0.328\n",
      "Epoch: [0][1128/2217]\t Loss: 0.327\n",
      "Epoch: [0][1129/2217]\t Loss: 0.327\n",
      "Epoch: [0][1130/2217]\t Loss: 0.327\n",
      "Epoch: [0][1131/2217]\t Loss: 0.326\n",
      "Epoch: [0][1132/2217]\t Loss: 0.326\n",
      "Epoch: [0][1133/2217]\t Loss: 0.326\n",
      "Epoch: [0][1134/2217]\t Loss: 0.325\n",
      "Epoch: [0][1135/2217]\t Loss: 0.325\n",
      "Epoch: [0][1136/2217]\t Loss: 0.325\n",
      "Epoch: [0][1137/2217]\t Loss: 0.325\n",
      "Epoch: [0][1138/2217]\t Loss: 0.324\n",
      "Epoch: [0][1139/2217]\t Loss: 0.324\n",
      "Epoch: [0][1140/2217]\t Loss: 0.324\n",
      "Epoch: [0][1141/2217]\t Loss: 0.323\n",
      "Epoch: [0][1142/2217]\t Loss: 0.323\n",
      "Epoch: [0][1143/2217]\t Loss: 0.323\n",
      "Epoch: [0][1144/2217]\t Loss: 0.322\n",
      "Epoch: [0][1145/2217]\t Loss: 0.322\n",
      "Epoch: [0][1146/2217]\t Loss: 0.322\n",
      "Epoch: [0][1147/2217]\t Loss: 0.322\n",
      "Epoch: [0][1148/2217]\t Loss: 0.321\n",
      "Epoch: [0][1149/2217]\t Loss: 0.321\n",
      "Epoch: [0][1150/2217]\t Loss: 0.321\n",
      "Epoch: [0][1151/2217]\t Loss: 0.320\n",
      "Epoch: [0][1152/2217]\t Loss: 0.320\n",
      "Epoch: [0][1153/2217]\t Loss: 0.320\n",
      "Epoch: [0][1154/2217]\t Loss: 0.320\n",
      "Epoch: [0][1155/2217]\t Loss: 0.319\n",
      "Epoch: [0][1156/2217]\t Loss: 0.319\n",
      "Epoch: [0][1157/2217]\t Loss: 0.319\n",
      "Epoch: [0][1158/2217]\t Loss: 0.318\n",
      "Epoch: [0][1159/2217]\t Loss: 0.318\n",
      "Epoch: [0][1160/2217]\t Loss: 0.318\n",
      "Epoch: [0][1161/2217]\t Loss: 0.318\n",
      "Epoch: [0][1162/2217]\t Loss: 0.317\n",
      "Epoch: [0][1163/2217]\t Loss: 0.317\n",
      "Epoch: [0][1164/2217]\t Loss: 0.317\n",
      "Epoch: [0][1165/2217]\t Loss: 0.316\n",
      "Epoch: [0][1166/2217]\t Loss: 0.316\n",
      "Epoch: [0][1167/2217]\t Loss: 0.316\n",
      "Epoch: [0][1168/2217]\t Loss: 0.316\n",
      "Epoch: [0][1169/2217]\t Loss: 0.315\n",
      "Epoch: [0][1170/2217]\t Loss: 0.315\n",
      "Epoch: [0][1171/2217]\t Loss: 0.315\n",
      "Epoch: [0][1172/2217]\t Loss: 0.314\n",
      "Epoch: [0][1173/2217]\t Loss: 0.314\n",
      "Epoch: [0][1174/2217]\t Loss: 0.314\n",
      "Epoch: [0][1175/2217]\t Loss: 0.314\n",
      "Epoch: [0][1176/2217]\t Loss: 0.313\n",
      "Epoch: [0][1177/2217]\t Loss: 0.313\n",
      "Epoch: [0][1178/2217]\t Loss: 0.313\n",
      "Epoch: [0][1179/2217]\t Loss: 0.312\n",
      "Epoch: [0][1180/2217]\t Loss: 0.312\n",
      "Epoch: [0][1181/2217]\t Loss: 0.312\n",
      "Epoch: [0][1182/2217]\t Loss: 0.312\n",
      "Epoch: [0][1183/2217]\t Loss: 0.311\n",
      "Epoch: [0][1184/2217]\t Loss: 0.311\n",
      "Epoch: [0][1185/2217]\t Loss: 0.311\n",
      "Epoch: [0][1186/2217]\t Loss: 0.310\n",
      "Epoch: [0][1187/2217]\t Loss: 0.310\n",
      "Epoch: [0][1188/2217]\t Loss: 0.310\n",
      "Epoch: [0][1189/2217]\t Loss: 0.310\n",
      "Epoch: [0][1190/2217]\t Loss: 0.309\n",
      "Epoch: [0][1191/2217]\t Loss: 0.309\n",
      "Epoch: [0][1192/2217]\t Loss: 0.309\n",
      "Epoch: [0][1193/2217]\t Loss: 0.309\n",
      "Epoch: [0][1194/2217]\t Loss: 0.308\n",
      "Epoch: [0][1195/2217]\t Loss: 0.308\n",
      "Epoch: [0][1196/2217]\t Loss: 0.308\n",
      "Epoch: [0][1197/2217]\t Loss: 0.307\n",
      "Epoch: [0][1198/2217]\t Loss: 0.307\n",
      "Epoch: [0][1199/2217]\t Loss: 0.307\n",
      "Epoch: [0][1200/2217]\t Loss: 0.306\n",
      "Epoch: [0][1201/2217]\t Loss: 0.306\n",
      "Epoch: [0][1202/2217]\t Loss: 0.306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][1203/2217]\t Loss: 0.306\n",
      "Epoch: [0][1204/2217]\t Loss: 0.305\n",
      "Epoch: [0][1205/2217]\t Loss: 0.305\n",
      "Epoch: [0][1206/2217]\t Loss: 0.305\n",
      "Epoch: [0][1207/2217]\t Loss: 0.305\n",
      "Epoch: [0][1208/2217]\t Loss: 0.304\n",
      "Epoch: [0][1209/2217]\t Loss: 0.304\n",
      "Epoch: [0][1210/2217]\t Loss: 0.304\n",
      "Epoch: [0][1211/2217]\t Loss: 0.303\n",
      "Epoch: [0][1212/2217]\t Loss: 0.303\n",
      "Epoch: [0][1213/2217]\t Loss: 0.303\n",
      "Epoch: [0][1214/2217]\t Loss: 0.303\n",
      "Epoch: [0][1215/2217]\t Loss: 0.302\n",
      "Epoch: [0][1216/2217]\t Loss: 0.302\n",
      "Epoch: [0][1217/2217]\t Loss: 0.302\n",
      "Epoch: [0][1218/2217]\t Loss: 0.301\n",
      "Epoch: [0][1219/2217]\t Loss: 0.301\n",
      "Epoch: [0][1220/2217]\t Loss: 0.301\n",
      "Epoch: [0][1221/2217]\t Loss: 0.300\n",
      "Epoch: [0][1222/2217]\t Loss: 0.300\n",
      "Epoch: [0][1223/2217]\t Loss: 0.300\n",
      "Epoch: [0][1224/2217]\t Loss: 0.300\n",
      "Epoch: [0][1225/2217]\t Loss: 0.299\n",
      "Epoch: [0][1226/2217]\t Loss: 0.299\n",
      "Epoch: [0][1227/2217]\t Loss: 0.299\n",
      "Epoch: [0][1228/2217]\t Loss: 0.299\n",
      "Epoch: [0][1229/2217]\t Loss: 0.298\n",
      "Epoch: [0][1230/2217]\t Loss: 0.298\n",
      "Epoch: [0][1231/2217]\t Loss: 0.298\n",
      "Epoch: [0][1232/2217]\t Loss: 0.297\n",
      "Epoch: [0][1233/2217]\t Loss: 0.297\n",
      "Epoch: [0][1234/2217]\t Loss: 0.297\n",
      "Epoch: [0][1235/2217]\t Loss: 0.297\n",
      "Epoch: [0][1236/2217]\t Loss: 0.296\n",
      "Epoch: [0][1237/2217]\t Loss: 0.296\n",
      "Epoch: [0][1238/2217]\t Loss: 0.296\n",
      "Epoch: [0][1239/2217]\t Loss: 0.296\n",
      "Epoch: [0][1240/2217]\t Loss: 0.295\n",
      "Epoch: [0][1241/2217]\t Loss: 0.295\n",
      "Epoch: [0][1242/2217]\t Loss: 0.295\n",
      "Epoch: [0][1243/2217]\t Loss: 0.294\n",
      "Epoch: [0][1244/2217]\t Loss: 0.294\n",
      "Epoch: [0][1245/2217]\t Loss: 0.294\n",
      "Epoch: [0][1246/2217]\t Loss: 0.294\n",
      "Epoch: [0][1247/2217]\t Loss: 0.293\n",
      "Epoch: [0][1248/2217]\t Loss: 0.293\n",
      "Epoch: [0][1249/2217]\t Loss: 0.293\n",
      "Epoch: [0][1250/2217]\t Loss: 0.293\n",
      "Epoch: [0][1251/2217]\t Loss: 0.292\n",
      "Epoch: [0][1252/2217]\t Loss: 0.292\n",
      "Epoch: [0][1253/2217]\t Loss: 0.292\n",
      "Epoch: [0][1254/2217]\t Loss: 0.292\n",
      "Epoch: [0][1255/2217]\t Loss: 0.291\n",
      "Epoch: [0][1256/2217]\t Loss: 0.291\n",
      "Epoch: [0][1257/2217]\t Loss: 0.291\n",
      "Epoch: [0][1258/2217]\t Loss: 0.291\n",
      "Epoch: [0][1259/2217]\t Loss: 0.290\n",
      "Epoch: [0][1260/2217]\t Loss: 0.290\n",
      "Epoch: [0][1261/2217]\t Loss: 0.290\n",
      "Epoch: [0][1262/2217]\t Loss: 0.290\n",
      "Epoch: [0][1263/2217]\t Loss: 0.289\n",
      "Epoch: [0][1264/2217]\t Loss: 0.289\n",
      "Epoch: [0][1265/2217]\t Loss: 0.289\n",
      "Epoch: [0][1266/2217]\t Loss: 0.289\n",
      "Epoch: [0][1267/2217]\t Loss: 0.288\n",
      "Epoch: [0][1268/2217]\t Loss: 0.288\n",
      "Epoch: [0][1269/2217]\t Loss: 0.288\n",
      "Epoch: [0][1270/2217]\t Loss: 0.287\n",
      "Epoch: [0][1271/2217]\t Loss: 0.287\n",
      "Epoch: [0][1272/2217]\t Loss: 0.287\n",
      "Epoch: [0][1273/2217]\t Loss: 0.287\n",
      "Epoch: [0][1274/2217]\t Loss: 0.286\n",
      "Epoch: [0][1275/2217]\t Loss: 0.286\n",
      "Epoch: [0][1276/2217]\t Loss: 0.286\n",
      "Epoch: [0][1277/2217]\t Loss: 0.286\n",
      "Epoch: [0][1278/2217]\t Loss: 0.285\n",
      "Epoch: [0][1279/2217]\t Loss: 0.285\n",
      "Epoch: [0][1280/2217]\t Loss: 0.285\n",
      "Epoch: [0][1281/2217]\t Loss: 0.285\n",
      "Epoch: [0][1282/2217]\t Loss: 0.285\n",
      "Epoch: [0][1283/2217]\t Loss: 0.284\n",
      "Epoch: [0][1284/2217]\t Loss: 0.284\n",
      "Epoch: [0][1285/2217]\t Loss: 0.284\n",
      "Epoch: [0][1286/2217]\t Loss: 0.284\n",
      "Epoch: [0][1287/2217]\t Loss: 0.283\n",
      "Epoch: [0][1288/2217]\t Loss: 0.283\n",
      "Epoch: [0][1289/2217]\t Loss: 0.283\n",
      "Epoch: [0][1290/2217]\t Loss: 0.282\n",
      "Epoch: [0][1291/2217]\t Loss: 0.282\n",
      "Epoch: [0][1292/2217]\t Loss: 0.282\n",
      "Epoch: [0][1293/2217]\t Loss: 0.282\n",
      "Epoch: [0][1294/2217]\t Loss: 0.281\n",
      "Epoch: [0][1295/2217]\t Loss: 0.281\n",
      "Epoch: [0][1296/2217]\t Loss: 0.281\n",
      "Epoch: [0][1297/2217]\t Loss: 0.281\n",
      "Epoch: [0][1298/2217]\t Loss: 0.280\n",
      "Epoch: [0][1299/2217]\t Loss: 0.280\n",
      "Epoch: [0][1300/2217]\t Loss: 0.280\n",
      "Epoch: [0][1301/2217]\t Loss: 0.280\n",
      "Epoch: [0][1302/2217]\t Loss: 0.279\n",
      "Epoch: [0][1303/2217]\t Loss: 0.279\n",
      "Epoch: [0][1304/2217]\t Loss: 0.279\n",
      "Epoch: [0][1305/2217]\t Loss: 0.279\n",
      "Epoch: [0][1306/2217]\t Loss: 0.278\n",
      "Epoch: [0][1307/2217]\t Loss: 0.278\n",
      "Epoch: [0][1308/2217]\t Loss: 0.278\n",
      "Epoch: [0][1309/2217]\t Loss: 0.278\n",
      "Epoch: [0][1310/2217]\t Loss: 0.277\n",
      "Epoch: [0][1311/2217]\t Loss: 0.277\n",
      "Epoch: [0][1312/2217]\t Loss: 0.277\n",
      "Epoch: [0][1313/2217]\t Loss: 0.277\n",
      "Epoch: [0][1314/2217]\t Loss: 0.276\n",
      "Epoch: [0][1315/2217]\t Loss: 0.276\n",
      "Epoch: [0][1316/2217]\t Loss: 0.276\n",
      "Epoch: [0][1317/2217]\t Loss: 0.276\n",
      "Epoch: [0][1318/2217]\t Loss: 0.275\n",
      "Epoch: [0][1319/2217]\t Loss: 0.275\n",
      "Epoch: [0][1320/2217]\t Loss: 0.275\n",
      "Epoch: [0][1321/2217]\t Loss: 0.275\n",
      "Epoch: [0][1322/2217]\t Loss: 0.274\n",
      "Epoch: [0][1323/2217]\t Loss: 0.274\n",
      "Epoch: [0][1324/2217]\t Loss: 0.274\n",
      "Epoch: [0][1325/2217]\t Loss: 0.274\n",
      "Epoch: [0][1326/2217]\t Loss: 0.273\n",
      "Epoch: [0][1327/2217]\t Loss: 0.273\n",
      "Epoch: [0][1328/2217]\t Loss: 0.273\n",
      "Epoch: [0][1329/2217]\t Loss: 0.273\n",
      "Epoch: [0][1330/2217]\t Loss: 0.272\n",
      "Epoch: [0][1331/2217]\t Loss: 0.272\n",
      "Epoch: [0][1332/2217]\t Loss: 0.272\n",
      "Epoch: [0][1333/2217]\t Loss: 0.272\n",
      "Epoch: [0][1334/2217]\t Loss: 0.271\n",
      "Epoch: [0][1335/2217]\t Loss: 0.271\n",
      "Epoch: [0][1336/2217]\t Loss: 0.271\n",
      "Epoch: [0][1337/2217]\t Loss: 0.271\n",
      "Epoch: [0][1338/2217]\t Loss: 0.270\n",
      "Epoch: [0][1339/2217]\t Loss: 0.270\n",
      "Epoch: [0][1340/2217]\t Loss: 0.270\n",
      "Epoch: [0][1341/2217]\t Loss: 0.270\n",
      "Epoch: [0][1342/2217]\t Loss: 0.269\n",
      "Epoch: [0][1343/2217]\t Loss: 0.269\n",
      "Epoch: [0][1344/2217]\t Loss: 0.269\n",
      "Epoch: [0][1345/2217]\t Loss: 0.269\n",
      "Epoch: [0][1346/2217]\t Loss: 0.268\n",
      "Epoch: [0][1347/2217]\t Loss: 0.268\n",
      "Epoch: [0][1348/2217]\t Loss: 0.268\n",
      "Epoch: [0][1349/2217]\t Loss: 0.268\n",
      "Epoch: [0][1350/2217]\t Loss: 0.267\n",
      "Epoch: [0][1351/2217]\t Loss: 0.267\n",
      "Epoch: [0][1352/2217]\t Loss: 0.267\n",
      "Epoch: [0][1353/2217]\t Loss: 0.267\n",
      "Epoch: [0][1354/2217]\t Loss: 0.267\n",
      "Epoch: [0][1355/2217]\t Loss: 0.266\n",
      "Epoch: [0][1356/2217]\t Loss: 0.266\n",
      "Epoch: [0][1357/2217]\t Loss: 0.266\n",
      "Epoch: [0][1358/2217]\t Loss: 0.266\n",
      "Epoch: [0][1359/2217]\t Loss: 0.265\n",
      "Epoch: [0][1360/2217]\t Loss: 0.265\n",
      "Epoch: [0][1361/2217]\t Loss: 0.265\n",
      "Epoch: [0][1362/2217]\t Loss: 0.265\n",
      "Epoch: [0][1363/2217]\t Loss: 0.264\n",
      "Epoch: [0][1364/2217]\t Loss: 0.264\n",
      "Epoch: [0][1365/2217]\t Loss: 0.264\n",
      "Epoch: [0][1366/2217]\t Loss: 0.264\n",
      "Epoch: [0][1367/2217]\t Loss: 0.263\n",
      "Epoch: [0][1368/2217]\t Loss: 0.263\n",
      "Epoch: [0][1369/2217]\t Loss: 0.263\n",
      "Epoch: [0][1370/2217]\t Loss: 0.263\n",
      "Epoch: [0][1371/2217]\t Loss: 0.262\n",
      "Epoch: [0][1372/2217]\t Loss: 0.262\n",
      "Epoch: [0][1373/2217]\t Loss: 0.262\n",
      "Epoch: [0][1374/2217]\t Loss: 0.262\n",
      "Epoch: [0][1375/2217]\t Loss: 0.262\n",
      "Epoch: [0][1376/2217]\t Loss: 0.261\n",
      "Epoch: [0][1377/2217]\t Loss: 0.261\n",
      "Epoch: [0][1378/2217]\t Loss: 0.261\n",
      "Epoch: [0][1379/2217]\t Loss: 0.261\n",
      "Epoch: [0][1380/2217]\t Loss: 0.261\n",
      "Epoch: [0][1381/2217]\t Loss: 0.260\n",
      "Epoch: [0][1382/2217]\t Loss: 0.260\n",
      "Epoch: [0][1383/2217]\t Loss: 0.260\n",
      "Epoch: [0][1384/2217]\t Loss: 0.260\n",
      "Epoch: [0][1385/2217]\t Loss: 0.259\n",
      "Epoch: [0][1386/2217]\t Loss: 0.259\n",
      "Epoch: [0][1387/2217]\t Loss: 0.259\n",
      "Epoch: [0][1388/2217]\t Loss: 0.259\n",
      "Epoch: [0][1389/2217]\t Loss: 0.259\n",
      "Epoch: [0][1390/2217]\t Loss: 0.258\n",
      "Epoch: [0][1391/2217]\t Loss: 0.258\n",
      "Epoch: [0][1392/2217]\t Loss: 0.258\n",
      "Epoch: [0][1393/2217]\t Loss: 0.258\n",
      "Epoch: [0][1394/2217]\t Loss: 0.257\n",
      "Epoch: [0][1395/2217]\t Loss: 0.257\n",
      "Epoch: [0][1396/2217]\t Loss: 0.257\n",
      "Epoch: [0][1397/2217]\t Loss: 0.257\n",
      "Epoch: [0][1398/2217]\t Loss: 0.256\n",
      "Epoch: [0][1399/2217]\t Loss: 0.256\n",
      "Epoch: [0][1400/2217]\t Loss: 0.256\n",
      "Epoch: [0][1401/2217]\t Loss: 0.256\n",
      "Epoch: [0][1402/2217]\t Loss: 0.255\n",
      "Epoch: [0][1403/2217]\t Loss: 0.255\n",
      "Epoch: [0][1404/2217]\t Loss: 0.255\n",
      "Epoch: [0][1405/2217]\t Loss: 0.255\n",
      "Epoch: [0][1406/2217]\t Loss: 0.254\n",
      "Epoch: [0][1407/2217]\t Loss: 0.254\n",
      "Epoch: [0][1408/2217]\t Loss: 0.254\n",
      "Epoch: [0][1409/2217]\t Loss: 0.254\n",
      "Epoch: [0][1410/2217]\t Loss: 0.254\n",
      "Epoch: [0][1411/2217]\t Loss: 0.253\n",
      "Epoch: [0][1412/2217]\t Loss: 0.253\n",
      "Epoch: [0][1413/2217]\t Loss: 0.253\n",
      "Epoch: [0][1414/2217]\t Loss: 0.253\n",
      "Epoch: [0][1415/2217]\t Loss: 0.252\n",
      "Epoch: [0][1416/2217]\t Loss: 0.252\n",
      "Epoch: [0][1417/2217]\t Loss: 0.252\n",
      "Epoch: [0][1418/2217]\t Loss: 0.252\n",
      "Epoch: [0][1419/2217]\t Loss: 0.252\n",
      "Epoch: [0][1420/2217]\t Loss: 0.251\n",
      "Epoch: [0][1421/2217]\t Loss: 0.251\n",
      "Epoch: [0][1422/2217]\t Loss: 0.251\n",
      "Epoch: [0][1423/2217]\t Loss: 0.251\n",
      "Epoch: [0][1424/2217]\t Loss: 0.251\n",
      "Epoch: [0][1425/2217]\t Loss: 0.250\n",
      "Epoch: [0][1426/2217]\t Loss: 0.250\n",
      "Epoch: [0][1427/2217]\t Loss: 0.250\n",
      "Epoch: [0][1428/2217]\t Loss: 0.250\n",
      "Epoch: [0][1429/2217]\t Loss: 0.249\n",
      "Epoch: [0][1430/2217]\t Loss: 0.249\n",
      "Epoch: [0][1431/2217]\t Loss: 0.249\n",
      "Epoch: [0][1432/2217]\t Loss: 0.249\n",
      "Epoch: [0][1433/2217]\t Loss: 0.248\n",
      "Epoch: [0][1434/2217]\t Loss: 0.248\n",
      "Epoch: [0][1435/2217]\t Loss: 0.248\n",
      "Epoch: [0][1436/2217]\t Loss: 0.248\n",
      "Epoch: [0][1437/2217]\t Loss: 0.248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][1438/2217]\t Loss: 0.247\n",
      "Epoch: [0][1439/2217]\t Loss: 0.247\n",
      "Epoch: [0][1440/2217]\t Loss: 0.247\n",
      "Epoch: [0][1441/2217]\t Loss: 0.247\n",
      "Epoch: [0][1442/2217]\t Loss: 0.246\n",
      "Epoch: [0][1443/2217]\t Loss: 0.246\n",
      "Epoch: [0][1444/2217]\t Loss: 0.246\n",
      "Epoch: [0][1445/2217]\t Loss: 0.246\n",
      "Epoch: [0][1446/2217]\t Loss: 0.245\n",
      "Epoch: [0][1447/2217]\t Loss: 0.245\n",
      "Epoch: [0][1448/2217]\t Loss: 0.245\n",
      "Epoch: [0][1449/2217]\t Loss: 0.245\n",
      "Epoch: [0][1450/2217]\t Loss: 0.245\n",
      "Epoch: [0][1451/2217]\t Loss: 0.244\n",
      "Epoch: [0][1452/2217]\t Loss: 0.244\n",
      "Epoch: [0][1453/2217]\t Loss: 0.244\n",
      "Epoch: [0][1454/2217]\t Loss: 0.244\n",
      "Epoch: [0][1455/2217]\t Loss: 0.244\n",
      "Epoch: [0][1456/2217]\t Loss: 0.243\n",
      "Epoch: [0][1457/2217]\t Loss: 0.243\n",
      "Epoch: [0][1458/2217]\t Loss: 0.243\n",
      "Epoch: [0][1459/2217]\t Loss: 0.243\n",
      "Epoch: [0][1460/2217]\t Loss: 0.243\n",
      "Epoch: [0][1461/2217]\t Loss: 0.242\n",
      "Epoch: [0][1462/2217]\t Loss: 0.242\n",
      "Epoch: [0][1463/2217]\t Loss: 0.242\n",
      "Epoch: [0][1464/2217]\t Loss: 0.242\n",
      "Epoch: [0][1465/2217]\t Loss: 0.242\n",
      "Epoch: [0][1466/2217]\t Loss: 0.241\n",
      "Epoch: [0][1467/2217]\t Loss: 0.241\n",
      "Epoch: [0][1468/2217]\t Loss: 0.241\n",
      "Epoch: [0][1469/2217]\t Loss: 0.241\n",
      "Epoch: [0][1470/2217]\t Loss: 0.240\n",
      "Epoch: [0][1471/2217]\t Loss: 0.240\n",
      "Epoch: [0][1472/2217]\t Loss: 0.240\n",
      "Epoch: [0][1473/2217]\t Loss: 0.240\n",
      "Epoch: [0][1474/2217]\t Loss: 0.240\n",
      "Epoch: [0][1475/2217]\t Loss: 0.239\n",
      "Epoch: [0][1476/2217]\t Loss: 0.239\n",
      "Epoch: [0][1477/2217]\t Loss: 0.239\n",
      "Epoch: [0][1478/2217]\t Loss: 0.239\n",
      "Epoch: [0][1479/2217]\t Loss: 0.239\n",
      "Epoch: [0][1480/2217]\t Loss: 0.238\n",
      "Epoch: [0][1481/2217]\t Loss: 0.238\n",
      "Epoch: [0][1482/2217]\t Loss: 0.238\n",
      "Epoch: [0][1483/2217]\t Loss: 0.238\n",
      "Epoch: [0][1484/2217]\t Loss: 0.238\n",
      "Epoch: [0][1485/2217]\t Loss: 0.237\n",
      "Epoch: [0][1486/2217]\t Loss: 0.237\n",
      "Epoch: [0][1487/2217]\t Loss: 0.237\n",
      "Epoch: [0][1488/2217]\t Loss: 0.237\n",
      "Epoch: [0][1489/2217]\t Loss: 0.236\n",
      "Epoch: [0][1490/2217]\t Loss: 0.236\n",
      "Epoch: [0][1491/2217]\t Loss: 0.236\n",
      "Epoch: [0][1492/2217]\t Loss: 0.236\n",
      "Epoch: [0][1493/2217]\t Loss: 0.236\n",
      "Epoch: [0][1494/2217]\t Loss: 0.235\n",
      "Epoch: [0][1495/2217]\t Loss: 0.235\n",
      "Epoch: [0][1496/2217]\t Loss: 0.235\n",
      "Epoch: [0][1497/2217]\t Loss: 0.235\n",
      "Epoch: [0][1498/2217]\t Loss: 0.235\n",
      "Epoch: [0][1499/2217]\t Loss: 0.234\n",
      "Epoch: [0][1500/2217]\t Loss: 0.234\n",
      "Epoch: [0][1501/2217]\t Loss: 0.234\n",
      "Epoch: [0][1502/2217]\t Loss: 0.234\n",
      "Epoch: [0][1503/2217]\t Loss: 0.233\n",
      "Epoch: [0][1504/2217]\t Loss: 0.233\n",
      "Epoch: [0][1505/2217]\t Loss: 0.233\n",
      "Epoch: [0][1506/2217]\t Loss: 0.233\n",
      "Epoch: [0][1507/2217]\t Loss: 0.233\n",
      "Epoch: [0][1508/2217]\t Loss: 0.232\n",
      "Epoch: [0][1509/2217]\t Loss: 0.232\n",
      "Epoch: [0][1510/2217]\t Loss: 0.232\n",
      "Epoch: [0][1511/2217]\t Loss: 0.232\n",
      "Epoch: [0][1512/2217]\t Loss: 0.232\n",
      "Epoch: [0][1513/2217]\t Loss: 0.231\n",
      "Epoch: [0][1514/2217]\t Loss: 0.231\n",
      "Epoch: [0][1515/2217]\t Loss: 0.231\n",
      "Epoch: [0][1516/2217]\t Loss: 0.231\n",
      "Epoch: [0][1517/2217]\t Loss: 0.231\n",
      "Epoch: [0][1518/2217]\t Loss: 0.230\n",
      "Epoch: [0][1519/2217]\t Loss: 0.230\n",
      "Epoch: [0][1520/2217]\t Loss: 0.230\n",
      "Epoch: [0][1521/2217]\t Loss: 0.230\n",
      "Epoch: [0][1522/2217]\t Loss: 0.230\n",
      "Epoch: [0][1523/2217]\t Loss: 0.230\n",
      "Epoch: [0][1524/2217]\t Loss: 0.229\n",
      "Epoch: [0][1525/2217]\t Loss: 0.229\n",
      "Epoch: [0][1526/2217]\t Loss: 0.229\n",
      "Epoch: [0][1527/2217]\t Loss: 0.229\n",
      "Epoch: [0][1528/2217]\t Loss: 0.229\n",
      "Epoch: [0][1529/2217]\t Loss: 0.228\n",
      "Epoch: [0][1530/2217]\t Loss: 0.228\n",
      "Epoch: [0][1531/2217]\t Loss: 0.228\n",
      "Epoch: [0][1532/2217]\t Loss: 0.228\n",
      "Epoch: [0][1533/2217]\t Loss: 0.228\n",
      "Epoch: [0][1534/2217]\t Loss: 0.227\n",
      "Epoch: [0][1535/2217]\t Loss: 0.227\n",
      "Epoch: [0][1536/2217]\t Loss: 0.227\n",
      "Epoch: [0][1537/2217]\t Loss: 0.227\n",
      "Epoch: [0][1538/2217]\t Loss: 0.227\n",
      "Epoch: [0][1539/2217]\t Loss: 0.226\n",
      "Epoch: [0][1540/2217]\t Loss: 0.226\n",
      "Epoch: [0][1541/2217]\t Loss: 0.226\n",
      "Epoch: [0][1542/2217]\t Loss: 0.226\n",
      "Epoch: [0][1543/2217]\t Loss: 0.226\n",
      "Epoch: [0][1544/2217]\t Loss: 0.225\n",
      "Epoch: [0][1545/2217]\t Loss: 0.225\n",
      "Epoch: [0][1546/2217]\t Loss: 0.225\n",
      "Epoch: [0][1547/2217]\t Loss: 0.225\n",
      "Epoch: [0][1548/2217]\t Loss: 0.225\n",
      "Epoch: [0][1549/2217]\t Loss: 0.224\n",
      "Epoch: [0][1550/2217]\t Loss: 0.224\n",
      "Epoch: [0][1551/2217]\t Loss: 0.224\n",
      "Epoch: [0][1552/2217]\t Loss: 0.224\n",
      "Epoch: [0][1553/2217]\t Loss: 0.224\n",
      "Epoch: [0][1554/2217]\t Loss: 0.223\n",
      "Epoch: [0][1555/2217]\t Loss: 0.223\n",
      "Epoch: [0][1556/2217]\t Loss: 0.223\n",
      "Epoch: [0][1557/2217]\t Loss: 0.223\n",
      "Epoch: [0][1558/2217]\t Loss: 0.223\n",
      "Epoch: [0][1559/2217]\t Loss: 0.223\n",
      "Epoch: [0][1560/2217]\t Loss: 0.222\n",
      "Epoch: [0][1561/2217]\t Loss: 0.222\n",
      "Epoch: [0][1562/2217]\t Loss: 0.222\n",
      "Epoch: [0][1563/2217]\t Loss: 0.222\n",
      "Epoch: [0][1564/2217]\t Loss: 0.222\n",
      "Epoch: [0][1565/2217]\t Loss: 0.221\n",
      "Epoch: [0][1566/2217]\t Loss: 0.221\n",
      "Epoch: [0][1567/2217]\t Loss: 0.221\n",
      "Epoch: [0][1568/2217]\t Loss: 0.221\n",
      "Epoch: [0][1569/2217]\t Loss: 0.221\n",
      "Epoch: [0][1570/2217]\t Loss: 0.220\n",
      "Epoch: [0][1571/2217]\t Loss: 0.220\n",
      "Epoch: [0][1572/2217]\t Loss: 0.220\n",
      "Epoch: [0][1573/2217]\t Loss: 0.220\n",
      "Epoch: [0][1574/2217]\t Loss: 0.220\n",
      "Epoch: [0][1575/2217]\t Loss: 0.220\n",
      "Epoch: [0][1576/2217]\t Loss: 0.219\n",
      "Epoch: [0][1577/2217]\t Loss: 0.219\n",
      "Epoch: [0][1578/2217]\t Loss: 0.219\n",
      "Epoch: [0][1579/2217]\t Loss: 0.219\n",
      "Epoch: [0][1580/2217]\t Loss: 0.219\n",
      "Epoch: [0][1581/2217]\t Loss: 0.218\n",
      "Epoch: [0][1582/2217]\t Loss: 0.218\n",
      "Epoch: [0][1583/2217]\t Loss: 0.218\n",
      "Epoch: [0][1584/2217]\t Loss: 0.218\n",
      "Epoch: [0][1585/2217]\t Loss: 0.218\n",
      "Epoch: [0][1586/2217]\t Loss: 0.217\n",
      "Epoch: [0][1587/2217]\t Loss: 0.217\n",
      "Epoch: [0][1588/2217]\t Loss: 0.217\n",
      "Epoch: [0][1589/2217]\t Loss: 0.217\n",
      "Epoch: [0][1590/2217]\t Loss: 0.217\n",
      "Epoch: [0][1591/2217]\t Loss: 0.217\n",
      "Epoch: [0][1592/2217]\t Loss: 0.216\n",
      "Epoch: [0][1593/2217]\t Loss: 0.216\n",
      "Epoch: [0][1594/2217]\t Loss: 0.216\n",
      "Epoch: [0][1595/2217]\t Loss: 0.216\n",
      "Epoch: [0][1596/2217]\t Loss: 0.216\n",
      "Epoch: [0][1597/2217]\t Loss: 0.216\n",
      "Epoch: [0][1598/2217]\t Loss: 0.215\n",
      "Epoch: [0][1599/2217]\t Loss: 0.215\n",
      "Epoch: [0][1600/2217]\t Loss: 0.215\n",
      "Epoch: [0][1601/2217]\t Loss: 0.215\n",
      "Epoch: [0][1602/2217]\t Loss: 0.215\n",
      "Epoch: [0][1603/2217]\t Loss: 0.214\n",
      "Epoch: [0][1604/2217]\t Loss: 0.214\n",
      "Epoch: [0][1605/2217]\t Loss: 0.214\n",
      "Epoch: [0][1606/2217]\t Loss: 0.214\n",
      "Epoch: [0][1607/2217]\t Loss: 0.214\n",
      "Epoch: [0][1608/2217]\t Loss: 0.214\n",
      "Epoch: [0][1609/2217]\t Loss: 0.213\n",
      "Epoch: [0][1610/2217]\t Loss: 0.213\n",
      "Epoch: [0][1611/2217]\t Loss: 0.213\n",
      "Epoch: [0][1612/2217]\t Loss: 0.213\n",
      "Epoch: [0][1613/2217]\t Loss: 0.213\n",
      "Epoch: [0][1614/2217]\t Loss: 0.212\n",
      "Epoch: [0][1615/2217]\t Loss: 0.212\n",
      "Epoch: [0][1616/2217]\t Loss: 0.212\n",
      "Epoch: [0][1617/2217]\t Loss: 0.212\n",
      "Epoch: [0][1618/2217]\t Loss: 0.212\n",
      "Epoch: [0][1619/2217]\t Loss: 0.212\n",
      "Epoch: [0][1620/2217]\t Loss: 0.211\n",
      "Epoch: [0][1621/2217]\t Loss: 0.211\n",
      "Epoch: [0][1622/2217]\t Loss: 0.211\n",
      "Epoch: [0][1623/2217]\t Loss: 0.211\n",
      "Epoch: [0][1624/2217]\t Loss: 0.211\n",
      "Epoch: [0][1625/2217]\t Loss: 0.210\n",
      "Epoch: [0][1626/2217]\t Loss: 0.210\n",
      "Epoch: [0][1627/2217]\t Loss: 0.210\n",
      "Epoch: [0][1628/2217]\t Loss: 0.210\n",
      "Epoch: [0][1629/2217]\t Loss: 0.210\n",
      "Epoch: [0][1630/2217]\t Loss: 0.210\n",
      "Epoch: [0][1631/2217]\t Loss: 0.209\n",
      "Epoch: [0][1632/2217]\t Loss: 0.209\n",
      "Epoch: [0][1633/2217]\t Loss: 0.209\n",
      "Epoch: [0][1634/2217]\t Loss: 0.209\n",
      "Epoch: [0][1635/2217]\t Loss: 0.209\n",
      "Epoch: [0][1636/2217]\t Loss: 0.209\n",
      "Epoch: [0][1637/2217]\t Loss: 0.208\n",
      "Epoch: [0][1638/2217]\t Loss: 0.208\n",
      "Epoch: [0][1639/2217]\t Loss: 0.208\n",
      "Epoch: [0][1640/2217]\t Loss: 0.208\n",
      "Epoch: [0][1641/2217]\t Loss: 0.208\n",
      "Epoch: [0][1642/2217]\t Loss: 0.207\n",
      "Epoch: [0][1643/2217]\t Loss: 0.207\n",
      "Epoch: [0][1644/2217]\t Loss: 0.207\n",
      "Epoch: [0][1645/2217]\t Loss: 0.207\n",
      "Epoch: [0][1646/2217]\t Loss: 0.207\n",
      "Epoch: [0][1647/2217]\t Loss: 0.207\n",
      "Epoch: [0][1648/2217]\t Loss: 0.206\n",
      "Epoch: [0][1649/2217]\t Loss: 0.206\n",
      "Epoch: [0][1650/2217]\t Loss: 0.206\n",
      "Epoch: [0][1651/2217]\t Loss: 0.206\n",
      "Epoch: [0][1652/2217]\t Loss: 0.206\n",
      "Epoch: [0][1653/2217]\t Loss: 0.206\n",
      "Epoch: [0][1654/2217]\t Loss: 0.205\n",
      "Epoch: [0][1655/2217]\t Loss: 0.205\n",
      "Epoch: [0][1656/2217]\t Loss: 0.205\n",
      "Epoch: [0][1657/2217]\t Loss: 0.205\n",
      "Epoch: [0][1658/2217]\t Loss: 0.205\n",
      "Epoch: [0][1659/2217]\t Loss: 0.204\n",
      "Epoch: [0][1660/2217]\t Loss: 0.204\n",
      "Epoch: [0][1661/2217]\t Loss: 0.204\n",
      "Epoch: [0][1662/2217]\t Loss: 0.204\n",
      "Epoch: [0][1663/2217]\t Loss: 0.204\n",
      "Epoch: [0][1664/2217]\t Loss: 0.204\n",
      "Epoch: [0][1665/2217]\t Loss: 0.203\n",
      "Epoch: [0][1666/2217]\t Loss: 0.203\n",
      "Epoch: [0][1667/2217]\t Loss: 0.203\n",
      "Epoch: [0][1668/2217]\t Loss: 0.203\n",
      "Epoch: [0][1669/2217]\t Loss: 0.203\n",
      "Epoch: [0][1670/2217]\t Loss: 0.203\n",
      "Epoch: [0][1671/2217]\t Loss: 0.202\n",
      "Epoch: [0][1672/2217]\t Loss: 0.202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][1673/2217]\t Loss: 0.202\n",
      "Epoch: [0][1674/2217]\t Loss: 0.202\n",
      "Epoch: [0][1675/2217]\t Loss: 0.202\n",
      "Epoch: [0][1676/2217]\t Loss: 0.201\n",
      "Epoch: [0][1677/2217]\t Loss: 0.201\n",
      "Epoch: [0][1678/2217]\t Loss: 0.201\n",
      "Epoch: [0][1679/2217]\t Loss: 0.201\n",
      "Epoch: [0][1680/2217]\t Loss: 0.201\n",
      "Epoch: [0][1681/2217]\t Loss: 0.201\n",
      "Epoch: [0][1682/2217]\t Loss: 0.200\n",
      "Epoch: [0][1683/2217]\t Loss: 0.200\n",
      "Epoch: [0][1684/2217]\t Loss: 0.200\n",
      "Epoch: [0][1685/2217]\t Loss: 0.200\n",
      "Epoch: [0][1686/2217]\t Loss: 0.200\n",
      "Epoch: [0][1687/2217]\t Loss: 0.200\n",
      "Epoch: [0][1688/2217]\t Loss: 0.199\n",
      "Epoch: [0][1689/2217]\t Loss: 0.199\n",
      "Epoch: [0][1690/2217]\t Loss: 0.199\n",
      "Epoch: [0][1691/2217]\t Loss: 0.199\n",
      "Epoch: [0][1692/2217]\t Loss: 0.199\n",
      "Epoch: [0][1693/2217]\t Loss: 0.198\n",
      "Epoch: [0][1694/2217]\t Loss: 0.198\n",
      "Epoch: [0][1695/2217]\t Loss: 0.198\n",
      "Epoch: [0][1696/2217]\t Loss: 0.198\n",
      "Epoch: [0][1697/2217]\t Loss: 0.198\n",
      "Epoch: [0][1698/2217]\t Loss: 0.198\n",
      "Epoch: [0][1699/2217]\t Loss: 0.197\n",
      "Epoch: [0][1700/2217]\t Loss: 0.197\n",
      "Epoch: [0][1701/2217]\t Loss: 0.197\n",
      "Epoch: [0][1702/2217]\t Loss: 0.197\n",
      "Epoch: [0][1703/2217]\t Loss: 0.197\n",
      "Epoch: [0][1704/2217]\t Loss: 0.197\n",
      "Epoch: [0][1705/2217]\t Loss: 0.196\n",
      "Epoch: [0][1706/2217]\t Loss: 0.196\n",
      "Epoch: [0][1707/2217]\t Loss: 0.196\n",
      "Epoch: [0][1708/2217]\t Loss: 0.196\n",
      "Epoch: [0][1709/2217]\t Loss: 0.196\n",
      "Epoch: [0][1710/2217]\t Loss: 0.196\n",
      "Epoch: [0][1711/2217]\t Loss: 0.195\n",
      "Epoch: [0][1712/2217]\t Loss: 0.195\n",
      "Epoch: [0][1713/2217]\t Loss: 0.195\n",
      "Epoch: [0][1714/2217]\t Loss: 0.195\n",
      "Epoch: [0][1715/2217]\t Loss: 0.195\n",
      "Epoch: [0][1716/2217]\t Loss: 0.195\n",
      "Epoch: [0][1717/2217]\t Loss: 0.194\n",
      "Epoch: [0][1718/2217]\t Loss: 0.194\n",
      "Epoch: [0][1719/2217]\t Loss: 0.194\n",
      "Epoch: [0][1720/2217]\t Loss: 0.194\n",
      "Epoch: [0][1721/2217]\t Loss: 0.194\n",
      "Epoch: [0][1722/2217]\t Loss: 0.193\n",
      "Epoch: [0][1723/2217]\t Loss: 0.193\n",
      "Epoch: [0][1724/2217]\t Loss: 0.193\n",
      "Epoch: [0][1725/2217]\t Loss: 0.193\n",
      "Epoch: [0][1726/2217]\t Loss: 0.193\n",
      "Epoch: [0][1727/2217]\t Loss: 0.193\n",
      "Epoch: [0][1728/2217]\t Loss: 0.193\n",
      "Epoch: [0][1729/2217]\t Loss: 0.192\n",
      "Epoch: [0][1730/2217]\t Loss: 0.192\n",
      "Epoch: [0][1731/2217]\t Loss: 0.192\n",
      "Epoch: [0][1732/2217]\t Loss: 0.192\n",
      "Epoch: [0][1733/2217]\t Loss: 0.192\n",
      "Epoch: [0][1734/2217]\t Loss: 0.192\n",
      "Epoch: [0][1735/2217]\t Loss: 0.191\n",
      "Epoch: [0][1736/2217]\t Loss: 0.191\n",
      "Epoch: [0][1737/2217]\t Loss: 0.191\n",
      "Epoch: [0][1738/2217]\t Loss: 0.191\n",
      "Epoch: [0][1739/2217]\t Loss: 0.191\n",
      "Epoch: [0][1740/2217]\t Loss: 0.190\n",
      "Epoch: [0][1741/2217]\t Loss: 0.190\n",
      "Epoch: [0][1742/2217]\t Loss: 0.190\n",
      "Epoch: [0][1743/2217]\t Loss: 0.190\n",
      "Epoch: [0][1744/2217]\t Loss: 0.190\n",
      "Epoch: [0][1745/2217]\t Loss: 0.190\n",
      "Epoch: [0][1746/2217]\t Loss: 0.189\n",
      "Epoch: [0][1747/2217]\t Loss: 0.189\n",
      "Epoch: [0][1748/2217]\t Loss: 0.189\n",
      "Epoch: [0][1749/2217]\t Loss: 0.189\n",
      "Epoch: [0][1750/2217]\t Loss: 0.189\n",
      "Epoch: [0][1751/2217]\t Loss: 0.189\n",
      "Epoch: [0][1752/2217]\t Loss: 0.189\n",
      "Epoch: [0][1753/2217]\t Loss: 0.188\n",
      "Epoch: [0][1754/2217]\t Loss: 0.188\n",
      "Epoch: [0][1755/2217]\t Loss: 0.188\n",
      "Epoch: [0][1756/2217]\t Loss: 0.188\n",
      "Epoch: [0][1757/2217]\t Loss: 0.188\n",
      "Epoch: [0][1758/2217]\t Loss: 0.188\n",
      "Epoch: [0][1759/2217]\t Loss: 0.187\n",
      "Epoch: [0][1760/2217]\t Loss: 0.187\n",
      "Epoch: [0][1761/2217]\t Loss: 0.187\n",
      "Epoch: [0][1762/2217]\t Loss: 0.187\n",
      "Epoch: [0][1763/2217]\t Loss: 0.187\n",
      "Epoch: [0][1764/2217]\t Loss: 0.187\n",
      "Epoch: [0][1765/2217]\t Loss: 0.186\n",
      "Epoch: [0][1766/2217]\t Loss: 0.186\n",
      "Epoch: [0][1767/2217]\t Loss: 0.186\n",
      "Epoch: [0][1768/2217]\t Loss: 0.186\n",
      "Epoch: [0][1769/2217]\t Loss: 0.186\n",
      "Epoch: [0][1770/2217]\t Loss: 0.186\n",
      "Epoch: [0][1771/2217]\t Loss: 0.185\n",
      "Epoch: [0][1772/2217]\t Loss: 0.185\n",
      "Epoch: [0][1773/2217]\t Loss: 0.185\n",
      "Epoch: [0][1774/2217]\t Loss: 0.185\n",
      "Epoch: [0][1775/2217]\t Loss: 0.185\n",
      "Epoch: [0][1776/2217]\t Loss: 0.185\n",
      "Epoch: [0][1777/2217]\t Loss: 0.185\n",
      "Epoch: [0][1778/2217]\t Loss: 0.184\n",
      "Epoch: [0][1779/2217]\t Loss: 0.184\n",
      "Epoch: [0][1780/2217]\t Loss: 0.184\n",
      "Epoch: [0][1781/2217]\t Loss: 0.184\n",
      "Epoch: [0][1782/2217]\t Loss: 0.184\n",
      "Epoch: [0][1783/2217]\t Loss: 0.184\n",
      "Epoch: [0][1784/2217]\t Loss: 0.183\n",
      "Epoch: [0][1785/2217]\t Loss: 0.183\n",
      "Epoch: [0][1786/2217]\t Loss: 0.183\n",
      "Epoch: [0][1787/2217]\t Loss: 0.183\n",
      "Epoch: [0][1788/2217]\t Loss: 0.183\n",
      "Epoch: [0][1789/2217]\t Loss: 0.183\n",
      "Epoch: [0][1790/2217]\t Loss: 0.182\n",
      "Epoch: [0][1791/2217]\t Loss: 0.182\n",
      "Epoch: [0][1792/2217]\t Loss: 0.182\n",
      "Epoch: [0][1793/2217]\t Loss: 0.182\n",
      "Epoch: [0][1794/2217]\t Loss: 0.182\n",
      "Epoch: [0][1795/2217]\t Loss: 0.182\n",
      "Epoch: [0][1796/2217]\t Loss: 0.181\n",
      "Epoch: [0][1797/2217]\t Loss: 0.181\n",
      "Epoch: [0][1798/2217]\t Loss: 0.181\n",
      "Epoch: [0][1799/2217]\t Loss: 0.181\n",
      "Epoch: [0][1800/2217]\t Loss: 0.181\n",
      "Epoch: [0][1801/2217]\t Loss: 0.181\n",
      "Epoch: [0][1802/2217]\t Loss: 0.181\n",
      "Epoch: [0][1803/2217]\t Loss: 0.180\n",
      "Epoch: [0][1804/2217]\t Loss: 0.180\n",
      "Epoch: [0][1805/2217]\t Loss: 0.180\n",
      "Epoch: [0][1806/2217]\t Loss: 0.180\n",
      "Epoch: [0][1807/2217]\t Loss: 0.180\n",
      "Epoch: [0][1808/2217]\t Loss: 0.180\n",
      "Epoch: [0][1809/2217]\t Loss: 0.179\n",
      "Epoch: [0][1810/2217]\t Loss: 0.179\n",
      "Epoch: [0][1811/2217]\t Loss: 0.179\n",
      "Epoch: [0][1812/2217]\t Loss: 0.179\n",
      "Epoch: [0][1813/2217]\t Loss: 0.179\n",
      "Epoch: [0][1814/2217]\t Loss: 0.179\n",
      "Epoch: [0][1815/2217]\t Loss: 0.179\n",
      "Epoch: [0][1816/2217]\t Loss: 0.178\n",
      "Epoch: [0][1817/2217]\t Loss: 0.178\n",
      "Epoch: [0][1818/2217]\t Loss: 0.178\n",
      "Epoch: [0][1819/2217]\t Loss: 0.178\n",
      "Epoch: [0][1820/2217]\t Loss: 0.178\n",
      "Epoch: [0][1821/2217]\t Loss: 0.178\n",
      "Epoch: [0][1822/2217]\t Loss: 0.178\n",
      "Epoch: [0][1823/2217]\t Loss: 0.177\n",
      "Epoch: [0][1824/2217]\t Loss: 0.177\n",
      "Epoch: [0][1825/2217]\t Loss: 0.177\n",
      "Epoch: [0][1826/2217]\t Loss: 0.177\n",
      "Epoch: [0][1827/2217]\t Loss: 0.177\n",
      "Epoch: [0][1828/2217]\t Loss: 0.177\n",
      "Epoch: [0][1829/2217]\t Loss: 0.176\n",
      "Epoch: [0][1830/2217]\t Loss: 0.176\n",
      "Epoch: [0][1831/2217]\t Loss: 0.176\n",
      "Epoch: [0][1832/2217]\t Loss: 0.176\n",
      "Epoch: [0][1833/2217]\t Loss: 0.176\n",
      "Epoch: [0][1834/2217]\t Loss: 0.176\n",
      "Epoch: [0][1835/2217]\t Loss: 0.175\n",
      "Epoch: [0][1836/2217]\t Loss: 0.175\n",
      "Epoch: [0][1837/2217]\t Loss: 0.175\n",
      "Epoch: [0][1838/2217]\t Loss: 0.175\n",
      "Epoch: [0][1839/2217]\t Loss: 0.175\n",
      "Epoch: [0][1840/2217]\t Loss: 0.175\n",
      "Epoch: [0][1841/2217]\t Loss: 0.175\n",
      "Epoch: [0][1842/2217]\t Loss: 0.174\n",
      "Epoch: [0][1843/2217]\t Loss: 0.174\n",
      "Epoch: [0][1844/2217]\t Loss: 0.174\n",
      "Epoch: [0][1845/2217]\t Loss: 0.174\n",
      "Epoch: [0][1846/2217]\t Loss: 0.174\n",
      "Epoch: [0][1847/2217]\t Loss: 0.174\n",
      "Epoch: [0][1848/2217]\t Loss: 0.174\n",
      "Epoch: [0][1849/2217]\t Loss: 0.173\n",
      "Epoch: [0][1850/2217]\t Loss: 0.173\n",
      "Epoch: [0][1851/2217]\t Loss: 0.173\n",
      "Epoch: [0][1852/2217]\t Loss: 0.173\n",
      "Epoch: [0][1853/2217]\t Loss: 0.173\n",
      "Epoch: [0][1854/2217]\t Loss: 0.173\n",
      "Epoch: [0][1855/2217]\t Loss: 0.173\n",
      "Epoch: [0][1856/2217]\t Loss: 0.173\n",
      "Epoch: [0][1857/2217]\t Loss: 0.172\n",
      "Epoch: [0][1858/2217]\t Loss: 0.172\n",
      "Epoch: [0][1859/2217]\t Loss: 0.172\n",
      "Epoch: [0][1860/2217]\t Loss: 0.172\n",
      "Epoch: [0][1861/2217]\t Loss: 0.172\n",
      "Epoch: [0][1862/2217]\t Loss: 0.172\n",
      "Epoch: [0][1863/2217]\t Loss: 0.171\n",
      "Epoch: [0][1864/2217]\t Loss: 0.171\n",
      "Epoch: [0][1865/2217]\t Loss: 0.171\n",
      "Epoch: [0][1866/2217]\t Loss: 0.171\n",
      "Epoch: [0][1867/2217]\t Loss: 0.171\n",
      "Epoch: [0][1868/2217]\t Loss: 0.171\n",
      "Epoch: [0][1869/2217]\t Loss: 0.171\n",
      "Epoch: [0][1870/2217]\t Loss: 0.170\n",
      "Epoch: [0][1871/2217]\t Loss: 0.170\n",
      "Epoch: [0][1872/2217]\t Loss: 0.170\n",
      "Epoch: [0][1873/2217]\t Loss: 0.170\n",
      "Epoch: [0][1874/2217]\t Loss: 0.170\n",
      "Epoch: [0][1875/2217]\t Loss: 0.170\n",
      "Epoch: [0][1876/2217]\t Loss: 0.170\n",
      "Epoch: [0][1877/2217]\t Loss: 0.169\n",
      "Epoch: [0][1878/2217]\t Loss: 0.169\n",
      "Epoch: [0][1879/2217]\t Loss: 0.169\n",
      "Epoch: [0][1880/2217]\t Loss: 0.169\n",
      "Epoch: [0][1881/2217]\t Loss: 0.169\n",
      "Epoch: [0][1882/2217]\t Loss: 0.169\n",
      "Epoch: [0][1883/2217]\t Loss: 0.169\n",
      "Epoch: [0][1884/2217]\t Loss: 0.168\n",
      "Epoch: [0][1885/2217]\t Loss: 0.168\n",
      "Epoch: [0][1886/2217]\t Loss: 0.168\n",
      "Epoch: [0][1887/2217]\t Loss: 0.168\n",
      "Epoch: [0][1888/2217]\t Loss: 0.168\n",
      "Epoch: [0][1889/2217]\t Loss: 0.168\n",
      "Epoch: [0][1890/2217]\t Loss: 0.168\n",
      "Epoch: [0][1891/2217]\t Loss: 0.167\n",
      "Epoch: [0][1892/2217]\t Loss: 0.167\n",
      "Epoch: [0][1893/2217]\t Loss: 0.167\n",
      "Epoch: [0][1894/2217]\t Loss: 0.167\n",
      "Epoch: [0][1895/2217]\t Loss: 0.167\n",
      "Epoch: [0][1896/2217]\t Loss: 0.167\n",
      "Epoch: [0][1897/2217]\t Loss: 0.167\n",
      "Epoch: [0][1898/2217]\t Loss: 0.166\n",
      "Epoch: [0][1899/2217]\t Loss: 0.166\n",
      "Epoch: [0][1900/2217]\t Loss: 0.166\n",
      "Epoch: [0][1901/2217]\t Loss: 0.166\n",
      "Epoch: [0][1902/2217]\t Loss: 0.166\n",
      "Epoch: [0][1903/2217]\t Loss: 0.166\n",
      "Epoch: [0][1904/2217]\t Loss: 0.166\n",
      "Epoch: [0][1905/2217]\t Loss: 0.166\n",
      "Epoch: [0][1906/2217]\t Loss: 0.165\n",
      "Epoch: [0][1907/2217]\t Loss: 0.165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][1908/2217]\t Loss: 0.165\n",
      "Epoch: [0][1909/2217]\t Loss: 0.165\n",
      "Epoch: [0][1910/2217]\t Loss: 0.165\n",
      "Epoch: [0][1911/2217]\t Loss: 0.165\n",
      "Epoch: [0][1912/2217]\t Loss: 0.165\n",
      "Epoch: [0][1913/2217]\t Loss: 0.164\n",
      "Epoch: [0][1914/2217]\t Loss: 0.164\n",
      "Epoch: [0][1915/2217]\t Loss: 0.164\n",
      "Epoch: [0][1916/2217]\t Loss: 0.164\n",
      "Epoch: [0][1917/2217]\t Loss: 0.164\n",
      "Epoch: [0][1918/2217]\t Loss: 0.164\n",
      "Epoch: [0][1919/2217]\t Loss: 0.164\n",
      "Epoch: [0][1920/2217]\t Loss: 0.163\n",
      "Epoch: [0][1921/2217]\t Loss: 0.163\n",
      "Epoch: [0][1922/2217]\t Loss: 0.163\n",
      "Epoch: [0][1923/2217]\t Loss: 0.163\n",
      "Epoch: [0][1924/2217]\t Loss: 0.163\n",
      "Epoch: [0][1925/2217]\t Loss: 0.163\n",
      "Epoch: [0][1926/2217]\t Loss: 0.162\n",
      "Epoch: [0][1927/2217]\t Loss: 0.162\n",
      "Epoch: [0][1928/2217]\t Loss: 0.162\n",
      "Epoch: [0][1929/2217]\t Loss: 0.162\n",
      "Epoch: [0][1930/2217]\t Loss: 0.162\n",
      "Epoch: [0][1931/2217]\t Loss: 0.162\n",
      "Epoch: [0][1932/2217]\t Loss: 0.162\n",
      "Epoch: [0][1933/2217]\t Loss: 0.161\n",
      "Epoch: [0][1934/2217]\t Loss: 0.161\n",
      "Epoch: [0][1935/2217]\t Loss: 0.161\n",
      "Epoch: [0][1936/2217]\t Loss: 0.161\n",
      "Epoch: [0][1937/2217]\t Loss: 0.161\n",
      "Epoch: [0][1938/2217]\t Loss: 0.161\n",
      "Epoch: [0][1939/2217]\t Loss: 0.161\n",
      "Epoch: [0][1940/2217]\t Loss: 0.161\n",
      "Epoch: [0][1941/2217]\t Loss: 0.160\n",
      "Epoch: [0][1942/2217]\t Loss: 0.160\n",
      "Epoch: [0][1943/2217]\t Loss: 0.160\n",
      "Epoch: [0][1944/2217]\t Loss: 0.160\n",
      "Epoch: [0][1945/2217]\t Loss: 0.160\n",
      "Epoch: [0][1946/2217]\t Loss: 0.160\n",
      "Epoch: [0][1947/2217]\t Loss: 0.160\n",
      "Epoch: [0][1948/2217]\t Loss: 0.159\n",
      "Epoch: [0][1949/2217]\t Loss: 0.159\n",
      "Epoch: [0][1950/2217]\t Loss: 0.159\n",
      "Epoch: [0][1951/2217]\t Loss: 0.159\n",
      "Epoch: [0][1952/2217]\t Loss: 0.159\n",
      "Epoch: [0][1953/2217]\t Loss: 0.159\n",
      "Epoch: [0][1954/2217]\t Loss: 0.159\n",
      "Epoch: [0][1955/2217]\t Loss: 0.158\n",
      "Epoch: [0][1956/2217]\t Loss: 0.158\n",
      "Epoch: [0][1957/2217]\t Loss: 0.158\n",
      "Epoch: [0][1958/2217]\t Loss: 0.158\n",
      "Epoch: [0][1959/2217]\t Loss: 0.158\n",
      "Epoch: [0][1960/2217]\t Loss: 0.158\n",
      "Epoch: [0][1961/2217]\t Loss: 0.158\n",
      "Epoch: [0][1962/2217]\t Loss: 0.157\n",
      "Epoch: [0][1963/2217]\t Loss: 0.157\n",
      "Epoch: [0][1964/2217]\t Loss: 0.157\n",
      "Epoch: [0][1965/2217]\t Loss: 0.157\n",
      "Epoch: [0][1966/2217]\t Loss: 0.157\n",
      "Epoch: [0][1967/2217]\t Loss: 0.157\n",
      "Epoch: [0][1968/2217]\t Loss: 0.157\n",
      "Epoch: [0][1969/2217]\t Loss: 0.156\n",
      "Epoch: [0][1970/2217]\t Loss: 0.156\n",
      "Epoch: [0][1971/2217]\t Loss: 0.156\n",
      "Epoch: [0][1972/2217]\t Loss: 0.156\n",
      "Epoch: [0][1973/2217]\t Loss: 0.156\n",
      "Epoch: [0][1974/2217]\t Loss: 0.156\n",
      "Epoch: [0][1975/2217]\t Loss: 0.156\n",
      "Epoch: [0][1976/2217]\t Loss: 0.155\n",
      "Epoch: [0][1977/2217]\t Loss: 0.155\n",
      "Epoch: [0][1978/2217]\t Loss: 0.155\n",
      "Epoch: [0][1979/2217]\t Loss: 0.155\n",
      "Epoch: [0][1980/2217]\t Loss: 0.155\n",
      "Epoch: [0][1981/2217]\t Loss: 0.155\n",
      "Epoch: [0][1982/2217]\t Loss: 0.155\n",
      "Epoch: [0][1983/2217]\t Loss: 0.155\n",
      "Epoch: [0][1984/2217]\t Loss: 0.154\n",
      "Epoch: [0][1985/2217]\t Loss: 0.154\n",
      "Epoch: [0][1986/2217]\t Loss: 0.154\n",
      "Epoch: [0][1987/2217]\t Loss: 0.154\n",
      "Epoch: [0][1988/2217]\t Loss: 0.154\n",
      "Epoch: [0][1989/2217]\t Loss: 0.154\n",
      "Epoch: [0][1990/2217]\t Loss: 0.154\n",
      "Epoch: [0][1991/2217]\t Loss: 0.154\n",
      "Epoch: [0][1992/2217]\t Loss: 0.153\n",
      "Epoch: [0][1993/2217]\t Loss: 0.153\n",
      "Epoch: [0][1994/2217]\t Loss: 0.153\n",
      "Epoch: [0][1995/2217]\t Loss: 0.153\n",
      "Epoch: [0][1996/2217]\t Loss: 0.153\n",
      "Epoch: [0][1997/2217]\t Loss: 0.153\n",
      "Epoch: [0][1998/2217]\t Loss: 0.153\n",
      "Epoch: [0][1999/2217]\t Loss: 0.153\n",
      "Epoch: [0][2000/2217]\t Loss: 0.152\n",
      "Epoch: [0][2001/2217]\t Loss: 0.152\n",
      "Epoch: [0][2002/2217]\t Loss: 0.152\n",
      "Epoch: [0][2003/2217]\t Loss: 0.152\n",
      "Epoch: [0][2004/2217]\t Loss: 0.152\n",
      "Epoch: [0][2005/2217]\t Loss: 0.152\n",
      "Epoch: [0][2006/2217]\t Loss: 0.152\n",
      "Epoch: [0][2007/2217]\t Loss: 0.152\n",
      "Epoch: [0][2008/2217]\t Loss: 0.151\n",
      "Epoch: [0][2009/2217]\t Loss: 0.151\n",
      "Epoch: [0][2010/2217]\t Loss: 0.151\n",
      "Epoch: [0][2011/2217]\t Loss: 0.151\n",
      "Epoch: [0][2012/2217]\t Loss: 0.151\n",
      "Epoch: [0][2013/2217]\t Loss: 0.151\n",
      "Epoch: [0][2014/2217]\t Loss: 0.151\n",
      "Epoch: [0][2015/2217]\t Loss: 0.151\n",
      "Epoch: [0][2016/2217]\t Loss: 0.150\n",
      "Epoch: [0][2017/2217]\t Loss: 0.150\n",
      "Epoch: [0][2018/2217]\t Loss: 0.150\n",
      "Epoch: [0][2019/2217]\t Loss: 0.150\n",
      "Epoch: [0][2020/2217]\t Loss: 0.150\n",
      "Epoch: [0][2021/2217]\t Loss: 0.150\n",
      "Epoch: [0][2022/2217]\t Loss: 0.150\n",
      "Epoch: [0][2023/2217]\t Loss: 0.149\n",
      "Epoch: [0][2024/2217]\t Loss: 0.149\n",
      "Epoch: [0][2025/2217]\t Loss: 0.149\n",
      "Epoch: [0][2026/2217]\t Loss: 0.149\n",
      "Epoch: [0][2027/2217]\t Loss: 0.149\n",
      "Epoch: [0][2028/2217]\t Loss: 0.149\n",
      "Epoch: [0][2029/2217]\t Loss: 0.149\n",
      "Epoch: [0][2030/2217]\t Loss: 0.149\n",
      "Epoch: [0][2031/2217]\t Loss: 0.149\n",
      "Epoch: [0][2032/2217]\t Loss: 0.148\n",
      "Epoch: [0][2033/2217]\t Loss: 0.148\n",
      "Epoch: [0][2034/2217]\t Loss: 0.148\n",
      "Epoch: [0][2035/2217]\t Loss: 0.148\n",
      "Epoch: [0][2036/2217]\t Loss: 0.148\n",
      "Epoch: [0][2037/2217]\t Loss: 0.148\n",
      "Epoch: [0][2038/2217]\t Loss: 0.148\n",
      "Epoch: [0][2039/2217]\t Loss: 0.148\n",
      "Epoch: [0][2040/2217]\t Loss: 0.147\n",
      "Epoch: [0][2041/2217]\t Loss: 0.147\n",
      "Epoch: [0][2042/2217]\t Loss: 0.147\n",
      "Epoch: [0][2043/2217]\t Loss: 0.147\n",
      "Epoch: [0][2044/2217]\t Loss: 0.147\n",
      "Epoch: [0][2045/2217]\t Loss: 0.147\n",
      "Epoch: [0][2046/2217]\t Loss: 0.147\n",
      "Epoch: [0][2047/2217]\t Loss: 0.147\n",
      "Epoch: [0][2048/2217]\t Loss: 0.146\n",
      "Epoch: [0][2049/2217]\t Loss: 0.146\n",
      "Epoch: [0][2050/2217]\t Loss: 0.146\n",
      "Epoch: [0][2051/2217]\t Loss: 0.146\n",
      "Epoch: [0][2052/2217]\t Loss: 0.146\n",
      "Epoch: [0][2053/2217]\t Loss: 0.146\n",
      "Epoch: [0][2054/2217]\t Loss: 0.146\n",
      "Epoch: [0][2055/2217]\t Loss: 0.146\n",
      "Epoch: [0][2056/2217]\t Loss: 0.145\n",
      "Epoch: [0][2057/2217]\t Loss: 0.145\n",
      "Epoch: [0][2058/2217]\t Loss: 0.145\n",
      "Epoch: [0][2059/2217]\t Loss: 0.145\n",
      "Epoch: [0][2060/2217]\t Loss: 0.145\n",
      "Epoch: [0][2061/2217]\t Loss: 0.145\n",
      "Epoch: [0][2062/2217]\t Loss: 0.145\n",
      "Epoch: [0][2063/2217]\t Loss: 0.144\n",
      "Epoch: [0][2064/2217]\t Loss: 0.144\n",
      "Epoch: [0][2065/2217]\t Loss: 0.144\n",
      "Epoch: [0][2066/2217]\t Loss: 0.144\n",
      "Epoch: [0][2067/2217]\t Loss: 0.144\n",
      "Epoch: [0][2068/2217]\t Loss: 0.144\n",
      "Epoch: [0][2069/2217]\t Loss: 0.144\n",
      "Epoch: [0][2070/2217]\t Loss: 0.144\n",
      "Epoch: [0][2071/2217]\t Loss: 0.144\n",
      "Epoch: [0][2072/2217]\t Loss: 0.143\n",
      "Epoch: [0][2073/2217]\t Loss: 0.143\n",
      "Epoch: [0][2074/2217]\t Loss: 0.143\n",
      "Epoch: [0][2075/2217]\t Loss: 0.143\n",
      "Epoch: [0][2076/2217]\t Loss: 0.143\n",
      "Epoch: [0][2077/2217]\t Loss: 0.143\n",
      "Epoch: [0][2078/2217]\t Loss: 0.143\n",
      "Epoch: [0][2079/2217]\t Loss: 0.143\n",
      "Epoch: [0][2080/2217]\t Loss: 0.142\n",
      "Epoch: [0][2081/2217]\t Loss: 0.142\n",
      "Epoch: [0][2082/2217]\t Loss: 0.142\n",
      "Epoch: [0][2083/2217]\t Loss: 0.142\n",
      "Epoch: [0][2084/2217]\t Loss: 0.142\n",
      "Epoch: [0][2085/2217]\t Loss: 0.142\n",
      "Epoch: [0][2086/2217]\t Loss: 0.142\n",
      "Epoch: [0][2087/2217]\t Loss: 0.141\n",
      "Epoch: [0][2088/2217]\t Loss: 0.141\n",
      "Epoch: [0][2089/2217]\t Loss: 0.141\n",
      "Epoch: [0][2090/2217]\t Loss: 0.141\n",
      "Epoch: [0][2091/2217]\t Loss: 0.141\n",
      "Epoch: [0][2092/2217]\t Loss: 0.141\n",
      "Epoch: [0][2093/2217]\t Loss: 0.141\n",
      "Epoch: [0][2094/2217]\t Loss: 0.141\n",
      "Epoch: [0][2095/2217]\t Loss: 0.140\n",
      "Epoch: [0][2096/2217]\t Loss: 0.140\n",
      "Epoch: [0][2097/2217]\t Loss: 0.140\n",
      "Epoch: [0][2098/2217]\t Loss: 0.140\n",
      "Epoch: [0][2099/2217]\t Loss: 0.140\n",
      "Epoch: [0][2100/2217]\t Loss: 0.140\n",
      "Epoch: [0][2101/2217]\t Loss: 0.140\n",
      "Epoch: [0][2102/2217]\t Loss: 0.140\n",
      "Epoch: [0][2103/2217]\t Loss: 0.140\n",
      "Epoch: [0][2104/2217]\t Loss: 0.139\n",
      "Epoch: [0][2105/2217]\t Loss: 0.139\n",
      "Epoch: [0][2106/2217]\t Loss: 0.139\n",
      "Epoch: [0][2107/2217]\t Loss: 0.139\n",
      "Epoch: [0][2108/2217]\t Loss: 0.139\n",
      "Epoch: [0][2109/2217]\t Loss: 0.139\n",
      "Epoch: [0][2110/2217]\t Loss: 0.139\n",
      "Epoch: [0][2111/2217]\t Loss: 0.139\n",
      "Epoch: [0][2112/2217]\t Loss: 0.138\n",
      "Epoch: [0][2113/2217]\t Loss: 0.138\n",
      "Epoch: [0][2114/2217]\t Loss: 0.138\n",
      "Epoch: [0][2115/2217]\t Loss: 0.138\n",
      "Epoch: [0][2116/2217]\t Loss: 0.138\n",
      "Epoch: [0][2117/2217]\t Loss: 0.138\n",
      "Epoch: [0][2118/2217]\t Loss: 0.138\n",
      "Epoch: [0][2119/2217]\t Loss: 0.138\n",
      "Epoch: [0][2120/2217]\t Loss: 0.138\n",
      "Epoch: [0][2121/2217]\t Loss: 0.137\n",
      "Epoch: [0][2122/2217]\t Loss: 0.137\n",
      "Epoch: [0][2123/2217]\t Loss: 0.137\n",
      "Epoch: [0][2124/2217]\t Loss: 0.137\n",
      "Epoch: [0][2125/2217]\t Loss: 0.137\n",
      "Epoch: [0][2126/2217]\t Loss: 0.137\n",
      "Epoch: [0][2127/2217]\t Loss: 0.137\n",
      "Epoch: [0][2128/2217]\t Loss: 0.137\n",
      "Epoch: [0][2129/2217]\t Loss: 0.136\n",
      "Epoch: [0][2130/2217]\t Loss: 0.136\n",
      "Epoch: [0][2131/2217]\t Loss: 0.136\n",
      "Epoch: [0][2132/2217]\t Loss: 0.136\n",
      "Epoch: [0][2133/2217]\t Loss: 0.136\n",
      "Epoch: [0][2134/2217]\t Loss: 0.136\n",
      "Epoch: [0][2135/2217]\t Loss: 0.136\n",
      "Epoch: [0][2136/2217]\t Loss: 0.136\n",
      "Epoch: [0][2137/2217]\t Loss: 0.136\n",
      "Epoch: [0][2138/2217]\t Loss: 0.135\n",
      "Epoch: [0][2139/2217]\t Loss: 0.135\n",
      "Epoch: [0][2140/2217]\t Loss: 0.135\n",
      "Epoch: [0][2141/2217]\t Loss: 0.135\n",
      "Epoch: [0][2142/2217]\t Loss: 0.135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][2143/2217]\t Loss: 0.135\n",
      "Epoch: [0][2144/2217]\t Loss: 0.135\n",
      "Epoch: [0][2145/2217]\t Loss: 0.135\n",
      "Epoch: [0][2146/2217]\t Loss: 0.134\n",
      "Epoch: [0][2147/2217]\t Loss: 0.134\n",
      "Epoch: [0][2148/2217]\t Loss: 0.134\n",
      "Epoch: [0][2149/2217]\t Loss: 0.134\n",
      "Epoch: [0][2150/2217]\t Loss: 0.134\n",
      "Epoch: [0][2151/2217]\t Loss: 0.134\n",
      "Epoch: [0][2152/2217]\t Loss: 0.134\n",
      "Epoch: [0][2153/2217]\t Loss: 0.134\n",
      "Epoch: [0][2154/2217]\t Loss: 0.134\n",
      "Epoch: [0][2155/2217]\t Loss: 0.133\n",
      "Epoch: [0][2156/2217]\t Loss: 0.133\n",
      "Epoch: [0][2157/2217]\t Loss: 0.133\n",
      "Epoch: [0][2158/2217]\t Loss: 0.133\n",
      "Epoch: [0][2159/2217]\t Loss: 0.133\n",
      "Epoch: [0][2160/2217]\t Loss: 0.133\n",
      "Epoch: [0][2161/2217]\t Loss: 0.133\n",
      "Epoch: [0][2162/2217]\t Loss: 0.133\n",
      "Epoch: [0][2163/2217]\t Loss: 0.132\n",
      "Epoch: [0][2164/2217]\t Loss: 0.132\n",
      "Epoch: [0][2165/2217]\t Loss: 0.132\n",
      "Epoch: [0][2166/2217]\t Loss: 0.132\n",
      "Epoch: [0][2167/2217]\t Loss: 0.132\n",
      "Epoch: [0][2168/2217]\t Loss: 0.132\n",
      "Epoch: [0][2169/2217]\t Loss: 0.132\n",
      "Epoch: [0][2170/2217]\t Loss: 0.132\n",
      "Epoch: [0][2171/2217]\t Loss: 0.132\n",
      "Epoch: [0][2172/2217]\t Loss: 0.131\n",
      "Epoch: [0][2173/2217]\t Loss: 0.131\n",
      "Epoch: [0][2174/2217]\t Loss: 0.131\n",
      "Epoch: [0][2175/2217]\t Loss: 0.131\n",
      "Epoch: [0][2176/2217]\t Loss: 0.131\n",
      "Epoch: [0][2177/2217]\t Loss: 0.131\n",
      "Epoch: [0][2178/2217]\t Loss: 0.131\n",
      "Epoch: [0][2179/2217]\t Loss: 0.131\n",
      "Epoch: [0][2180/2217]\t Loss: 0.130\n",
      "Epoch: [0][2181/2217]\t Loss: 0.130\n",
      "Epoch: [0][2182/2217]\t Loss: 0.130\n",
      "Epoch: [0][2183/2217]\t Loss: 0.130\n",
      "Epoch: [0][2184/2217]\t Loss: 0.130\n",
      "Epoch: [0][2185/2217]\t Loss: 0.130\n",
      "Epoch: [0][2186/2217]\t Loss: 0.130\n",
      "Epoch: [0][2187/2217]\t Loss: 0.130\n",
      "Epoch: [0][2188/2217]\t Loss: 0.129\n",
      "Epoch: [0][2189/2217]\t Loss: 0.129\n",
      "Epoch: [0][2190/2217]\t Loss: 0.129\n",
      "Epoch: [0][2191/2217]\t Loss: 0.129\n",
      "Epoch: [0][2192/2217]\t Loss: 0.129\n",
      "Epoch: [0][2193/2217]\t Loss: 0.129\n",
      "Epoch: [0][2194/2217]\t Loss: 0.129\n",
      "Epoch: [0][2195/2217]\t Loss: 0.129\n",
      "Epoch: [0][2196/2217]\t Loss: 0.129\n",
      "Epoch: [0][2197/2217]\t Loss: 0.128\n",
      "Epoch: [0][2198/2217]\t Loss: 0.128\n",
      "Epoch: [0][2199/2217]\t Loss: 0.128\n",
      "Epoch: [0][2200/2217]\t Loss: 0.128\n",
      "Epoch: [0][2201/2217]\t Loss: 0.128\n",
      "Epoch: [0][2202/2217]\t Loss: 0.128\n",
      "Epoch: [0][2203/2217]\t Loss: 0.128\n",
      "Epoch: [0][2204/2217]\t Loss: 0.128\n",
      "Epoch: [0][2205/2217]\t Loss: 0.128\n",
      "Epoch: [0][2206/2217]\t Loss: 0.127\n",
      "Epoch: [0][2207/2217]\t Loss: 0.127\n",
      "Epoch: [0][2208/2217]\t Loss: 0.127\n",
      "Epoch: [0][2209/2217]\t Loss: 0.127\n",
      "Epoch: [0][2210/2217]\t Loss: 0.127\n",
      "Epoch: [0][2211/2217]\t Loss: 0.127\n",
      "Epoch: [0][2212/2217]\t Loss: 0.127\n",
      "Epoch: [0][2213/2217]\t Loss: 0.127\n",
      "Epoch: [0][2214/2217]\t Loss: 0.126\n",
      "Epoch: [0][2215/2217]\t Loss: 0.126\n",
      "Epoch: [0][2216/2217]\t Loss: 0.126\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    train(train_loader, transformer, transformer_optimizer, criterion, epoch, print_every=1)\n",
    "    state_dict = {'epoch': epoch, 'transformer': transformer, 'transformer_optimizer': transformer_optimizer}\n",
    "    torch.save(state_dict, '../models/checkpoint_{}.pth.tar'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a7cb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval\n",
    "\n",
    "checkpoint = torch.load('../models/checkpoint_{}.tar'.format())\n",
    "transformer = checkpoint['transformer']\n",
    "\n",
    "while(1):\n",
    "    question = input('Question: ')\n",
    "    if question == 'q':\n",
    "        break\n",
    "    max_len = input('Max len of words you want to generate: ')\n",
    "    enc_qus = [word_map(word, word_map['<unk>']) for word in question.split()]\n",
    "    question = torch.LongTensor(enc_qus).to(device).unsqueeze(0)\n",
    "    question_mask = (question != 0).to(device).unsqueeze(1).unsqueeze(1)\n",
    "    sentence = evaluate(transformer, question, question_mask, max_len, word_map)\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea94001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b830455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c7f22c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
